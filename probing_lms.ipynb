{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Probing Language Models__\n",
    "\n",
    "This notebook serves as a start for your NLP2 assignment on probing Language Models. This notebook will become part of the contents that you will submit at the end, so make sure to keep your code (somewhat) clean :-)\n",
    "\n",
    "__note__: This assignment is not dependent on big fancy GPUs. I run all this stuff on my own 3 year old CPU, without any Colab hassle. So it's up to you to decide how you want to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "For the Transformer models you are advised to make use of the `transformers` library of Huggingface: https://github.com/huggingface/transformers\n",
    "Their library is well documented, and they provide great tools to easily load in pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## Your code for initializing the transformer model(s)\n",
    "#\n",
    "# Note that most transformer models use their own `tokenizer`, that should be loaded in as well.\n",
    "#\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## Your code for initializing the rnn model(s)\n",
    "#\n",
    "# The Gulordava LSTM model can be found here: \n",
    "# https://drive.google.com/file/d/19Lp3AM4NEPycp_IBgoHfLc_V456pmUom/view?usp=sharing\n",
    "# You can read more about this model in the original paper here: https://arxiv.org/pdf/1803.11138.pdf\n",
    "#\n",
    "# N.B: I have altered the RNNModel code to only output the hidden states that you are interested in.\n",
    "# If you want to do more experiments with this model you could have a look at the original code here:\n",
    "# https://github.com/facebookresearch/colorlessgreenRNNs/blob/master/src/language_models/model.py\n",
    "#\n",
    "from collections import defaultdict\n",
    "from lstm.model import RNNModel\n",
    "import torch\n",
    "\n",
    "\n",
    "model_location = 'state_dict.pt'  # <- point this to the location of the Gulordava .pt file\n",
    "lstm = RNNModel('LSTM', 50001, 650, 650, 2)\n",
    "lstm.load_state_dict(torch.load(model_location))\n",
    "\n",
    "\n",
    "# This LSTM does not use a Tokenizer like the Transformers, but a Vocab dictionary that maps a token to an id.\n",
    "with open('lstm/vocab.txt', encoding=\"utf8\") as f:\n",
    "    w2i = {w.strip(): i for i, w in enumerate(f)}\n",
    "\n",
    "vocab = defaultdict(lambda: w2i[\"<unk>\"])\n",
    "vocab.update(w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea that before you move on, you try to feed some text to your LMs; and check if everything works accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "For this assignment you will train your probes on __treebank__ corpora. A treebank is a corpus that has been *parsed*, and stored in a representation that allows the parse tree to be recovered. Next to a parse tree, treebanks also often contain information about part-of-speech tags, which is exactly what we are after now.\n",
    "\n",
    "The treebank you will use for now is part of the Universal Dependencies project. I provide a sample of this treebank as well, so you can test your setup on that before moving on to larger amounts of data.\n",
    "\n",
    "Make sure you accustom yourself to the format that is created by the `conllu` library that parses the treebank files before moving on. For example, make sure you understand how you can access the pos tag of a token, or how to cope with the tree structure that is formed using the `to_tree()` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA\n",
    "from typing import List\n",
    "from conllu import parse_incr, TokenList\n",
    "\n",
    "\n",
    "# If stuff like `: str` and `-> ..` seems scary, fear not! \n",
    "# These are type hints that help you to understand what kind of argument and output is expected.\n",
    "def parse_corpus(filename: str) -> List[TokenList]:\n",
    "    data_file = open(filename, encoding=\"utf-8\")\n",
    "\n",
    "    ud_parses = list(parse_incr(data_file))\n",
    "    \n",
    "    return ud_parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TokenList<Al, -, Zaman, :, American, forces, killed, Shaikh, Abdullah, al, -, Ani, ,, the, preacher, at, the, mosque, in, the, town, of, Qaim, ,, near, the, Syrian, border, .>, TokenList<[, This, killing, of, a, respected, cleric, will, be, causing, us, trouble, for, years, to, come, ., ]>, TokenList<DPA, :, Iraqi, authorities, announced, that, they, had, busted, up, 3, terrorist, cells, operating, in, Baghdad, .>, TokenList<Two, of, them, were, being, run, by, 2, officials, of, the, Ministry, of, the, Interior, !>, TokenList<The, MoI, in, Iraq, is, equivalent, to, the, US, FBI, ,, so, this, would, be, like, having, J., Edgar, Hoover, unwittingly, employ, at, a, high, level, members, of, the, Weathermen, bombers, back, in, the, 1960s, .>, TokenList<The, third, was, being, run, by, the, head, of, an, investment, firm, .>, TokenList<You, wonder, if, he, was, manipulating, the, market, with, his, bombing, targets, .>, TokenList<The, cells, were, operating, in, the, Ghazaliyah, and, al, -, Jihad, districts, of, the, capital, .>, TokenList<Although, the, announcement, was, probably, made, to, show, progress, in, identifying, and, breaking, up, terror, cells, ,, I, do, n't, find, the, news, that, the, Baathists, continue, to, penetrate, the, Iraqi, government, very, hopeful, .>, TokenList<It, reminds, me, too, much, of, the, ARVN, officers, who, were, secretly, working, for, the, other, side, in, Vietnam, .>]\n"
     ]
    }
   ],
   "source": [
    "ud_parses = parse_corpus(\"data/en_ewt-ud-train.conllu\")\n",
    "print(ud_parses[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Representations\n",
    "\n",
    "We now have our data all set, our models are running and we are good to go!\n",
    "\n",
    "The next step is now to create the model representations for the sentences in our corpora. Once we have generated these representations we can store them, and train additional diagnostic (/probing) classifiers on top of the representations.\n",
    "\n",
    "There are a few things you should keep in mind here. Read these carefully, as these tips will save you a lot of time in your implementation.\n",
    "1. Transformer models make use of Byte-Pair Encodings (BPE), that chunk up a piece of next in subword pieces. For example, a word such as \"largely\" could be chunked up into \"large\" and \"ly\". We are interested in probing linguistic information on the __word__-level. Therefore, we will follow the suggestion of Hewitt et al. (2019a, footnote 4), and create the representation of a word by averaging over the representations of its subwords. So the representation of \"largely\" becomes the average of that of \"large\" and \"ly\".\n",
    "\n",
    "\n",
    "2. Subword chunks never overlap multiple tokens. In other words, say we have a phrase like \"None of the\", then the tokenizer might chunk that into \"No\"+\"ne\"+\" of\"+\" the\", but __not__ into \"No\"+\"ne o\"+\"f the\", as those chunks overlap multiple tokens. This is great for our setup! Otherwise it would have been quite challenging to distribute the representation of a subword over the 2 tokens it belongs to.\n",
    "\n",
    "\n",
    "3. **Important**: If you closely examine the provided treebank, you will notice that some tokens are split up into multiple pieces, that each have their own POS-tag. For example, in the first sentence the word \"Al-Zaman\" is split into \"Al\", \"-\", and \"Zaman\". In such cases, the conllu `TokenList` format will add the following attribute: `('misc', OrderedDict([('SpaceAfter', 'No')]))` to these tokens. Your model's tokenizer does not need to adhere to the same tokenization. E.g., \"Al-Zaman\" could be split into \"Al-\"+\"Za\"+\"man\", making it hard to match the representations with their correct pos-tag. Therefore I recommend you to not tokenize your entire sentence at once, but to do this based on the chunking of the treebank. <br /><br />\n",
    "Make sure to still incoporate the spaces in a sentence though, as these are part of the BPE of the tokenizer. That is, the tokenizer uses a different token id for `\"man\"`, than it does for `\" man\"`: the former could be part of `\" woman\"`=`\" wo`\"+`\"man\"`, whereas the latter would be the used in case *man* occurs at the start of a word. The tokenizer for GPT-2 adds spaces at the start of a token (represented as a `Ä ` symbol). This means that you should keep track whether the previous token had the `SpaceAfter` attribute set to `'No'`: in case it did not, you should manually prepend a `\" \"` ahead of the token.\n",
    "\n",
    "\n",
    "4. The LSTM LM does not have the issues related to subwords, but is far more restricted in its vocabulary. Make sure you keep the above points in mind though, when creating the LSTM representations. You might want to write separate functions for the LSTM, but that is up to you.\n",
    "\n",
    "\n",
    "5. The huggingface transformer models don't return the hidden state by default. To achieve this you can pass `output_hidden_states=True` to a model forward pass. The hidden states are then returned for all intermediate layers as well, the latest entry in this list corresponds to the top layer.\n",
    "\n",
    "\n",
    "6. **N.B.**: Make sure that when you run a sentence through your model, you do so within a `with torch.no_grad():` block, and that you have run `model.eval()` beforehand as well (to disable dropout).\n",
    "\n",
    "\n",
    "7. **N.B.**: Make sure to use a token's ``[\"form\"]`` attribute, and not the ``[\"lemma\"]``, as the latter will stem any relevant morphological information from the token. We don't want this, because we want to feed well-formed, grammatical sentences to our model.\n",
    "\n",
    "\n",
    "I would like to stress that if you feel hindered in any way by the simple code structure that is presented here, you are free to modify it :-) Just make sure it is clear to an outsider what you're doing, some helpful comments never hurt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FETCH SENTENCE REPRESENTATIONS\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Should return a tensor of shape (num_tokens_in_corpus, representation_size)\n",
    "# Make sure you correctly average the subword representations that belong to 1 token!\n",
    "\n",
    "def fetch_sen_reps(ud_parses: List[TokenList], model, tokenizer) -> Tensor:\n",
    "    representation_size = 768\n",
    "    out = []\n",
    "    out = torch.empty(1, representation_size)\n",
    "    index = 0\n",
    "    \n",
    "    for sentence in tqdm(ud_parses):\n",
    "        j = 0\n",
    "        concat_dict = {}\n",
    "        token_list = []\n",
    "        space_after = False\n",
    "        for token in sentence:\n",
    "            \n",
    "            test_var = token[\"misc\"]\n",
    "            \n",
    "            if space_after:\n",
    "                token_return = tokenizer.encode(str(token), add_prefix_space=True)\n",
    "            else:\n",
    "                token_return = tokenizer.encode(str(token))\n",
    "            if test_var:\n",
    "                space_after = False\n",
    "            else:\n",
    "                space_after = True        \n",
    "            \n",
    "            len_i = len(token_return)\n",
    "            concat_dict[j] = [j+i for i in range(len_i)]\n",
    "            j += len_i\n",
    "            token_list += token_return\n",
    "            #(token_list.append(token) for token in token_return)\n",
    "        token_list = torch.LongTensor(token_list)\n",
    "        #print(token_list)\n",
    "        #token_dict[\"input_ids\"] = torch.cat(token_dict[\"input_ids\"], axis=-1)\n",
    "        #token_dict[\"attention_mask\"] = torch.cat(token_dict[\"attention_mask\"], axis=-1)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            out_sentence = model(input_ids = token_list, output_hidden_states=True)\n",
    "        out_sentence = out_sentence[\"hidden_states\"][-1].squeeze()  \n",
    "        \n",
    "        \n",
    "        out_sent = torch.zeros(len(sentence), representation_size)\n",
    "        for i, key in enumerate(concat_dict):\n",
    "            out_sent[i] = torch.mean(out_sentence[concat_dict[key]], axis=0)\n",
    "        out = torch.cat([out, out_sent])\n",
    "\n",
    "    return out[1:][:]      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def fetch_sen_reps_lstm(ud_parses: List[TokenList], model, tokenizer) -> Tensor:\n",
    "    representation_size = 650\n",
    "    out = torch.zeros(1, representation_size)\n",
    "    for sentence in tqdm(ud_parses):\n",
    "        sent = []\n",
    "        for token in sentence:\n",
    "            sent.append(tokenizer[str(token)])\n",
    "        sent = torch.LongTensor(sent)\n",
    "        hidden = model.init_hidden(2)\n",
    "        print(sent.shape)\n",
    "        with torch.no_grad():\n",
    "            print(hidden[0].shape)\n",
    "            model.eval()\n",
    "            out_sentence = model(sent, hidden[0])\n",
    "\n",
    "        out = torch.cat([out, out_sentence])\n",
    "    return out[1:][:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate your activation extraction procedure I have set up the following assertion function as a sanity check. It compares your representation against a pickled version of mine. \n",
    "\n",
    "For this I used `distilgpt2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:00<00:00, 11.53it/s]\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29])\n",
      "torch.Size([2, 2, 650])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12942/3377868607.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0massert_sen_reps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_12942/3377868607.py\u001b[0m in \u001b[0;36massert_sen_reps\u001b[0;34m(model, tokenizer, lstm, vocab)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mown_distilgpt2_emb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_sen_reps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mown_lstm_emb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_sen_reps_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdistilgpt2_emb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mown_distilgpt2_emb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12942/618712831.py\u001b[0m in \u001b[0;36mfetch_sen_reps_lstm\u001b[0;34m(ud_parses, model, tokenizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mout_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/nlp2-probing-lms/lstm/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, output_vocab_probs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_vocab_probs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_vocab_probs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;31m# See torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    607\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    199\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m    200\u001b[0m                     expected_input_dim, input.dim()))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "def error_msg(model_name, gold_embs, embs, i2w):\n",
    "    with open(f'{model_name}_tokens1.pickle', 'rb') as f:\n",
    "        sen_tokens = pickle.load(f)\n",
    "        \n",
    "    diff = torch.abs(embs - gold_embs)\n",
    "    max_diff = torch.max(diff)\n",
    "    avg_diff = torch.mean(diff)\n",
    "    \n",
    "    print(f\"{model_name} embeddings don't match!\")\n",
    "    print(f\"Max diff.: {max_diff:.4f}\\nMean diff. {avg_diff:.4f}\")\n",
    "\n",
    "    print(\"\\nCheck if your tokenization matches with the original tokenization:\")\n",
    "    for idx in sen_tokens.squeeze():\n",
    "        if isinstance(i2w, list):\n",
    "            token = i2w[idx]\n",
    "        else:\n",
    "            token = i2w.convert_ids_to_tokens(idx.item())\n",
    "        print(f\"{idx:<6} {token}\")\n",
    "\n",
    "\n",
    "def assert_sen_reps(model, tokenizer, lstm, vocab):\n",
    "    with open('distilgpt2_emb1.pickle', 'rb') as f:\n",
    "        distilgpt2_emb1 = pickle.load(f)\n",
    "        \n",
    "    with open('lstm_emb1.pickle', 'rb') as f:\n",
    "        lstm_emb1 = pickle.load(f)\n",
    "    \n",
    "    corpus = parse_corpus('data/sample/en_ewt-ud-train.conllu')[:1]\n",
    "    \n",
    "    own_distilgpt2_emb1 = fetch_sen_reps(corpus, model, tokenizer)\n",
    "    own_lstm_emb1 = fetch_sen_reps_lstm(corpus, lstm, vocab)\n",
    "    \n",
    "    assert distilgpt2_emb1.shape == own_distilgpt2_emb1.shape, \\\n",
    "        f\"Distilgpt2 shape mismatch: {distilgpt2_emb1.shape} (gold) vs. {own_distilgpt2_emb1.shape} (yours)\"\n",
    "    assert lstm_emb1.shape == own_lstm_emb1.shape, \\\n",
    "        f\"LSTM shape mismatch: {lstm_emb1.shape} (gold) vs. {own_lstm_emb1.shape} (yours)\"\n",
    "\n",
    "    if not torch.allclose(distilgpt2_emb1, own_distilgpt2_emb1, rtol=1e-3, atol=1e-3):\n",
    "        error_msg(\"distilgpt2\", distilgpt2_emb1, own_distilgpt2_emb1, tokenizer)\n",
    "    if not torch.allclose(lstm_emb1, own_lstm_emb1, rtol=1e-3, atol=1e-3):\n",
    "        error_msg(\"lstm\", lstm_emb1, own_lstm_emb1, list(vocab.keys()))\n",
    "\n",
    "\n",
    "assert_sen_reps(model, tokenizer, lstm, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we should define a function that extracts the corresponding POS labels for each activation, which we do based on the **``\"upostag\"``** attribute of a token (so not the ``xpostag`` attribute). These labels will be transformed to a tensor containing the label index for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FETCH POS LABELS\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Should return a tensor of shape (num_tokens_in_corpus,)\n",
    "# Make sure that when fetching these pos tags for your train/dev/test corpora you share the label vocabulary.\n",
    "def fetch_pos_tags(ud_parses: List[TokenList], pos_vocab=None) -> Tensor:\n",
    "    pos_tags = list()\n",
    "    pos_vocab = defaultdict(lambda:\"UNK\")\n",
    "    for sentence in ud_parses:\n",
    "        for token in sentence:\n",
    "\n",
    "            pos_tags.append(token[\"upostag\"])\n",
    "\n",
    "    if pos_vocab:\n",
    "        targets = pos_vocab.fit_transform(pos_tags)\n",
    "        pos_tags = torch.as_tensor(targets)\n",
    "    else:\n",
    "        pos_vocab = preprocessing.LabelEncoder()\n",
    "        targets = pos_vocab.fit_transform(pos_tags)\n",
    "        pos_tags = torch.as_tensor(targets)\n",
    "  \n",
    "    return pos_tags, pos_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââ| 90/90 [00:04<00:00, 19.66it/s]\n",
      "100%|âââââââââââââââââââââââââââââââââââââââââââ| 50/50 [00:02<00:00, 18.28it/s]\n",
      "100%|âââââââââââââââââââââââââââââââââââââââââââ| 50/50 [00:03<00:00, 15.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function that combines the previous functions, and creates 2 tensors for a .conllu file: \n",
    "# 1 containing the token representations, and 1 containing the (tokenized) pos_tags.\n",
    "\n",
    "def create_data(filename: str, lm, w2i, pos_vocab=None):\n",
    "    ud_parses = parse_corpus(filename)\n",
    "    \n",
    "    sen_reps = fetch_sen_reps(ud_parses, lm, w2i)\n",
    "    pos_tags, pos_vocab = fetch_pos_tags(ud_parses, pos_vocab=pos_vocab)\n",
    "    \n",
    "    return sen_reps, pos_tags, pos_vocab\n",
    "\n",
    "\n",
    "lm = model  # or `lstm`\n",
    "w2i = tokenizer  # or `vocab`\n",
    "use_sample = True\n",
    "\n",
    "train_x, train_y, train_vocab = create_data(\n",
    "    os.path.join('data', 'sample' if use_sample else '', 'en_ewt-ud-train.conllu'),\n",
    "    lm, \n",
    "    w2i\n",
    ")\n",
    "\n",
    "dev_x, dev_y, _ = create_data(\n",
    "    os.path.join('data', 'sample' if use_sample else '', 'en_ewt-ud-dev.conllu'),\n",
    "    lm, \n",
    "    w2i,\n",
    "    pos_vocab=train_vocab\n",
    ")\n",
    "\n",
    "test_x, test_y, _ = create_data(\n",
    "    os.path.join('data', 'sample' if use_sample else '', 'en_ewt-ud-test.conllu'),\n",
    "    lm,\n",
    "    w2i,\n",
    "    pos_vocab=train_vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic Classification\n",
    "\n",
    "We now have our models, our data, _and_ our representations all set! Hurray, well done. We can finally move onto the cool stuff, i.e. training the diagnostic classifiers (DCs).\n",
    "\n",
    "DCs are simple in their complexity on purpose. To read more about why this is the case you could already have a look at the \"Designing and Interpreting Probes with Control Tasks\" by Hewitt and Liang (esp. Sec. 3.2).\n",
    "\n",
    "A simple linear classifier will suffice for now, don't bother with adding fancy non-linearities to it.\n",
    "\n",
    "I am personally a fan of the `skorch` library, that provides `sklearn`-like functionalities for training `torch` models, but you are free to train your dc using whatever method you prefer.\n",
    "\n",
    "As this is an Artificial Intelligence master and you have all done ML1 + DL, I expect you to use your train/dev/test splits correctly ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                       | 29/10000 [00:00<01:13, 135.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.7740, grad_fn=<NllLossBackward>)\n",
      "Validation accuracy on batch 0: 0.17924527823925018\n",
      "Training accuracy on batch 0: 0.018252933397889137\n",
      "tensor(21.1231, grad_fn=<NllLossBackward>)\n",
      "tensor(50.6898, grad_fn=<NllLossBackward>)\n",
      "tensor(70.5067, grad_fn=<NllLossBackward>)\n",
      "tensor(74.3555, grad_fn=<NllLossBackward>)\n",
      "tensor(82.7960, grad_fn=<NllLossBackward>)\n",
      "tensor(60.7454, grad_fn=<NllLossBackward>)\n",
      "tensor(69.3444, grad_fn=<NllLossBackward>)\n",
      "tensor(87.4475, grad_fn=<NllLossBackward>)\n",
      "tensor(99.7461, grad_fn=<NllLossBackward>)\n",
      "tensor(92.9311, grad_fn=<NllLossBackward>)\n",
      "tensor(90.4405, grad_fn=<NllLossBackward>)\n",
      "tensor(104.0150, grad_fn=<NllLossBackward>)\n",
      "tensor(86.5882, grad_fn=<NllLossBackward>)\n",
      "tensor(83.2456, grad_fn=<NllLossBackward>)\n",
      "tensor(67.4583, grad_fn=<NllLossBackward>)\n",
      "tensor(53.5467, grad_fn=<NllLossBackward>)\n",
      "tensor(74.0160, grad_fn=<NllLossBackward>)\n",
      "tensor(93.8645, grad_fn=<NllLossBackward>)\n",
      "tensor(97.6027, grad_fn=<NllLossBackward>)\n",
      "tensor(98.8790, grad_fn=<NllLossBackward>)\n",
      "tensor(93.0616, grad_fn=<NllLossBackward>)\n",
      "tensor(93.5725, grad_fn=<NllLossBackward>)\n",
      "tensor(91.0178, grad_fn=<NllLossBackward>)\n",
      "tensor(108.2674, grad_fn=<NllLossBackward>)\n",
      "tensor(90.1646, grad_fn=<NllLossBackward>)\n",
      "tensor(80.4539, grad_fn=<NllLossBackward>)\n",
      "tensor(83.4357, grad_fn=<NllLossBackward>)\n",
      "tensor(91.8762, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|â                                      | 47/10000 [00:00<01:09, 143.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(98.6807, grad_fn=<NllLossBackward>)\n",
      "tensor(91.9845, grad_fn=<NllLossBackward>)\n",
      "tensor(115.2502, grad_fn=<NllLossBackward>)\n",
      "tensor(124.8854, grad_fn=<NllLossBackward>)\n",
      "tensor(123.1066, grad_fn=<NllLossBackward>)\n",
      "tensor(98.3102, grad_fn=<NllLossBackward>)\n",
      "tensor(81.9631, grad_fn=<NllLossBackward>)\n",
      "tensor(92.1862, grad_fn=<NllLossBackward>)\n",
      "tensor(114.3640, grad_fn=<NllLossBackward>)\n",
      "tensor(100.3338, grad_fn=<NllLossBackward>)\n",
      "tensor(97.5223, grad_fn=<NllLossBackward>)\n",
      "tensor(94.8409, grad_fn=<NllLossBackward>)\n",
      "tensor(97.8218, grad_fn=<NllLossBackward>)\n",
      "tensor(98.2615, grad_fn=<NllLossBackward>)\n",
      "tensor(100.3355, grad_fn=<NllLossBackward>)\n",
      "tensor(80.4512, grad_fn=<NllLossBackward>)\n",
      "tensor(65.1576, grad_fn=<NllLossBackward>)\n",
      "tensor(63.7601, grad_fn=<NllLossBackward>)\n",
      "tensor(59.4647, grad_fn=<NllLossBackward>)\n",
      "tensor(64.1868, grad_fn=<NllLossBackward>)\n",
      "tensor(85.0068, grad_fn=<NllLossBackward>)\n",
      "tensor(88.4556, grad_fn=<NllLossBackward>)\n",
      "tensor(77.9966, grad_fn=<NllLossBackward>)\n",
      "tensor(92.7360, grad_fn=<NllLossBackward>)\n",
      "tensor(96.0266, grad_fn=<NllLossBackward>)\n",
      "tensor(92.6644, grad_fn=<NllLossBackward>)\n",
      "tensor(56.1727, grad_fn=<NllLossBackward>)\n",
      "tensor(55.0450, grad_fn=<NllLossBackward>)\n",
      "tensor(59.0583, grad_fn=<NllLossBackward>)\n",
      "tensor(76.3152, grad_fn=<NllLossBackward>)\n",
      "tensor(93.4355, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â                                      | 75/10000 [00:00<01:11, 138.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.6070, grad_fn=<NllLossBackward>)\n",
      "tensor(89.9115, grad_fn=<NllLossBackward>)\n",
      "tensor(87.3600, grad_fn=<NllLossBackward>)\n",
      "tensor(82.2230, grad_fn=<NllLossBackward>)\n",
      "tensor(72.0085, grad_fn=<NllLossBackward>)\n",
      "tensor(66.3880, grad_fn=<NllLossBackward>)\n",
      "tensor(67.8638, grad_fn=<NllLossBackward>)\n",
      "tensor(80.1076, grad_fn=<NllLossBackward>)\n",
      "tensor(63.4794, grad_fn=<NllLossBackward>)\n",
      "tensor(44.9035, grad_fn=<NllLossBackward>)\n",
      "tensor(57.7877, grad_fn=<NllLossBackward>)\n",
      "tensor(67.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(72.5613, grad_fn=<NllLossBackward>)\n",
      "tensor(59.9937, grad_fn=<NllLossBackward>)\n",
      "tensor(45.6675, grad_fn=<NllLossBackward>)\n",
      "tensor(61.2709, grad_fn=<NllLossBackward>)\n",
      "tensor(75.5285, grad_fn=<NllLossBackward>)\n",
      "tensor(71.4792, grad_fn=<NllLossBackward>)\n",
      "tensor(65.9326, grad_fn=<NllLossBackward>)\n",
      "tensor(58.9413, grad_fn=<NllLossBackward>)\n",
      "tensor(64.0142, grad_fn=<NllLossBackward>)\n",
      "tensor(75.0656, grad_fn=<NllLossBackward>)\n",
      "tensor(89.4310, grad_fn=<NllLossBackward>)\n",
      "tensor(103.9186, grad_fn=<NllLossBackward>)\n",
      "tensor(106.6702, grad_fn=<NllLossBackward>)\n",
      "tensor(79.8495, grad_fn=<NllLossBackward>)\n",
      "tensor(61.8735, grad_fn=<NllLossBackward>)\n",
      "tensor(38.4501, grad_fn=<NllLossBackward>)\n",
      "tensor(50.9549, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â                                     | 105/10000 [00:00<01:10, 140.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(51.2712, grad_fn=<NllLossBackward>)\n",
      "tensor(55.1270, grad_fn=<NllLossBackward>)\n",
      "tensor(60.9157, grad_fn=<NllLossBackward>)\n",
      "tensor(72.2622, grad_fn=<NllLossBackward>)\n",
      "tensor(70.2320, grad_fn=<NllLossBackward>)\n",
      "tensor(63.2917, grad_fn=<NllLossBackward>)\n",
      "tensor(53.4818, grad_fn=<NllLossBackward>)\n",
      "tensor(61.0517, grad_fn=<NllLossBackward>)\n",
      "tensor(54.0620, grad_fn=<NllLossBackward>)\n",
      "tensor(56.1531, grad_fn=<NllLossBackward>)\n",
      "tensor(68.2152, grad_fn=<NllLossBackward>)\n",
      "tensor(57.9378, grad_fn=<NllLossBackward>)\n",
      "tensor(67.9624, grad_fn=<NllLossBackward>)\n",
      "tensor(73.8857, grad_fn=<NllLossBackward>)\n",
      "tensor(70.1688, grad_fn=<NllLossBackward>)\n",
      "tensor(59.8860, grad_fn=<NllLossBackward>)\n",
      "tensor(65.0458, grad_fn=<NllLossBackward>)\n",
      "tensor(78.6009, grad_fn=<NllLossBackward>)\n",
      "tensor(79.7422, grad_fn=<NllLossBackward>)\n",
      "tensor(75.4553, grad_fn=<NllLossBackward>)\n",
      "tensor(76.3774, grad_fn=<NllLossBackward>)\n",
      "tensor(82.3710, grad_fn=<NllLossBackward>)\n",
      "tensor(94.8304, grad_fn=<NllLossBackward>)\n",
      "tensor(93.5535, grad_fn=<NllLossBackward>)\n",
      "tensor(66.9684, grad_fn=<NllLossBackward>)\n",
      "tensor(42.6356, grad_fn=<NllLossBackward>)\n",
      "tensor(56.8814, grad_fn=<NllLossBackward>)\n",
      "tensor(65.6857, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â                                     | 134/10000 [00:00<01:11, 138.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(61.5657, grad_fn=<NllLossBackward>)\n",
      "tensor(51.9282, grad_fn=<NllLossBackward>)\n",
      "tensor(43.8955, grad_fn=<NllLossBackward>)\n",
      "tensor(53.9689, grad_fn=<NllLossBackward>)\n",
      "tensor(51.6047, grad_fn=<NllLossBackward>)\n",
      "tensor(57.8704, grad_fn=<NllLossBackward>)\n",
      "tensor(50.8546, grad_fn=<NllLossBackward>)\n",
      "tensor(39.9618, grad_fn=<NllLossBackward>)\n",
      "tensor(38.9954, grad_fn=<NllLossBackward>)\n",
      "tensor(45.4563, grad_fn=<NllLossBackward>)\n",
      "tensor(47.3957, grad_fn=<NllLossBackward>)\n",
      "tensor(25.4230, grad_fn=<NllLossBackward>)\n",
      "tensor(32.5014, grad_fn=<NllLossBackward>)\n",
      "tensor(38.7557, grad_fn=<NllLossBackward>)\n",
      "tensor(38.1583, grad_fn=<NllLossBackward>)\n",
      "tensor(32.7552, grad_fn=<NllLossBackward>)\n",
      "tensor(42.4834, grad_fn=<NllLossBackward>)\n",
      "tensor(40.6926, grad_fn=<NllLossBackward>)\n",
      "tensor(38.8481, grad_fn=<NllLossBackward>)\n",
      "tensor(42.0228, grad_fn=<NllLossBackward>)\n",
      "tensor(50.8893, grad_fn=<NllLossBackward>)\n",
      "tensor(52.1141, grad_fn=<NllLossBackward>)\n",
      "tensor(47.3524, grad_fn=<NllLossBackward>)\n",
      "tensor(48.2833, grad_fn=<NllLossBackward>)\n",
      "tensor(51.0461, grad_fn=<NllLossBackward>)\n",
      "tensor(49.0126, grad_fn=<NllLossBackward>)\n",
      "tensor(44.1403, grad_fn=<NllLossBackward>)\n",
      "tensor(31.1474, grad_fn=<NllLossBackward>)\n",
      "tensor(34.6346, grad_fn=<NllLossBackward>)\n",
      "tensor(43.8461, grad_fn=<NllLossBackward>)\n",
      "tensor(48.3974, grad_fn=<NllLossBackward>)\n",
      "tensor(49.9151, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â                                     | 166/10000 [00:01<01:14, 131.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(57.5735, grad_fn=<NllLossBackward>)\n",
      "tensor(51.3147, grad_fn=<NllLossBackward>)\n",
      "tensor(54.5226, grad_fn=<NllLossBackward>)\n",
      "tensor(65.9311, grad_fn=<NllLossBackward>)\n",
      "tensor(67.1746, grad_fn=<NllLossBackward>)\n",
      "tensor(56.5004, grad_fn=<NllLossBackward>)\n",
      "tensor(50.7304, grad_fn=<NllLossBackward>)\n",
      "tensor(49.7523, grad_fn=<NllLossBackward>)\n",
      "tensor(50.6478, grad_fn=<NllLossBackward>)\n",
      "tensor(61.4180, grad_fn=<NllLossBackward>)\n",
      "tensor(56.2055, grad_fn=<NllLossBackward>)\n",
      "tensor(47.4480, grad_fn=<NllLossBackward>)\n",
      "tensor(51.7985, grad_fn=<NllLossBackward>)\n",
      "tensor(53.7643, grad_fn=<NllLossBackward>)\n",
      "tensor(54.0066, grad_fn=<NllLossBackward>)\n",
      "tensor(57.0225, grad_fn=<NllLossBackward>)\n",
      "tensor(58.6819, grad_fn=<NllLossBackward>)\n",
      "tensor(47.6096, grad_fn=<NllLossBackward>)\n",
      "tensor(48.3600, grad_fn=<NllLossBackward>)\n",
      "tensor(40.0868, grad_fn=<NllLossBackward>)\n",
      "tensor(39.8764, grad_fn=<NllLossBackward>)\n",
      "tensor(46.0994, grad_fn=<NllLossBackward>)\n",
      "tensor(41.2978, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â                                     | 198/10000 [00:01<01:08, 143.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(34.2668, grad_fn=<NllLossBackward>)\n",
      "tensor(48.8369, grad_fn=<NllLossBackward>)\n",
      "tensor(50.0401, grad_fn=<NllLossBackward>)\n",
      "tensor(47.1444, grad_fn=<NllLossBackward>)\n",
      "tensor(32.6394, grad_fn=<NllLossBackward>)\n",
      "tensor(43.5112, grad_fn=<NllLossBackward>)\n",
      "tensor(45.3978, grad_fn=<NllLossBackward>)\n",
      "tensor(43.8917, grad_fn=<NllLossBackward>)\n",
      "tensor(43.6629, grad_fn=<NllLossBackward>)\n",
      "tensor(55.7296, grad_fn=<NllLossBackward>)\n",
      "tensor(45.9361, grad_fn=<NllLossBackward>)\n",
      "tensor(35.2744, grad_fn=<NllLossBackward>)\n",
      "tensor(35.8853, grad_fn=<NllLossBackward>)\n",
      "tensor(35.1977, grad_fn=<NllLossBackward>)\n",
      "tensor(34.2830, grad_fn=<NllLossBackward>)\n",
      "tensor(36.1601, grad_fn=<NllLossBackward>)\n",
      "tensor(36.4884, grad_fn=<NllLossBackward>)\n",
      "tensor(37.1296, grad_fn=<NllLossBackward>)\n",
      "tensor(37.1727, grad_fn=<NllLossBackward>)\n",
      "tensor(38.3939, grad_fn=<NllLossBackward>)\n",
      "tensor(36.0959, grad_fn=<NllLossBackward>)\n",
      "tensor(33.9338, grad_fn=<NllLossBackward>)\n",
      "tensor(44.0834, grad_fn=<NllLossBackward>)\n",
      "tensor(48.9300, grad_fn=<NllLossBackward>)\n",
      "tensor(43.1381, grad_fn=<NllLossBackward>)\n",
      "tensor(41.2144, grad_fn=<NllLossBackward>)\n",
      "tensor(42.7233, grad_fn=<NllLossBackward>)\n",
      "tensor(47.2164, grad_fn=<NllLossBackward>)\n",
      "tensor(42.3611, grad_fn=<NllLossBackward>)\n",
      "tensor(43.3002, grad_fn=<NllLossBackward>)\n",
      "tensor(43.3991, grad_fn=<NllLossBackward>)\n",
      "tensor(45.3655, grad_fn=<NllLossBackward>)\n",
      "tensor(44.1907, grad_fn=<NllLossBackward>)\n",
      "tensor(44.3687, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â                                     | 235/10000 [00:01<01:00, 160.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46.7358, grad_fn=<NllLossBackward>)\n",
      "tensor(26.8485, grad_fn=<NllLossBackward>)\n",
      "tensor(20.0935, grad_fn=<NllLossBackward>)\n",
      "tensor(24.4649, grad_fn=<NllLossBackward>)\n",
      "tensor(29.8718, grad_fn=<NllLossBackward>)\n",
      "tensor(27.8020, grad_fn=<NllLossBackward>)\n",
      "tensor(34.6884, grad_fn=<NllLossBackward>)\n",
      "tensor(31.2236, grad_fn=<NllLossBackward>)\n",
      "tensor(34.2347, grad_fn=<NllLossBackward>)\n",
      "tensor(45.8524, grad_fn=<NllLossBackward>)\n",
      "tensor(46.0419, grad_fn=<NllLossBackward>)\n",
      "tensor(47.4420, grad_fn=<NllLossBackward>)\n",
      "tensor(43.3613, grad_fn=<NllLossBackward>)\n",
      "tensor(39.2570, grad_fn=<NllLossBackward>)\n",
      "tensor(39.7323, grad_fn=<NllLossBackward>)\n",
      "tensor(28.8421, grad_fn=<NllLossBackward>)\n",
      "tensor(35.1440, grad_fn=<NllLossBackward>)\n",
      "tensor(41.0111, grad_fn=<NllLossBackward>)\n",
      "tensor(37.6866, grad_fn=<NllLossBackward>)\n",
      "tensor(34.5745, grad_fn=<NllLossBackward>)\n",
      "tensor(38.4783, grad_fn=<NllLossBackward>)\n",
      "tensor(45.5094, grad_fn=<NllLossBackward>)\n",
      "tensor(31.7554, grad_fn=<NllLossBackward>)\n",
      "tensor(30.2816, grad_fn=<NllLossBackward>)\n",
      "tensor(28.9996, grad_fn=<NllLossBackward>)\n",
      "tensor(37.6110, grad_fn=<NllLossBackward>)\n",
      "tensor(42.0427, grad_fn=<NllLossBackward>)\n",
      "tensor(44.0663, grad_fn=<NllLossBackward>)\n",
      "tensor(39.5901, grad_fn=<NllLossBackward>)\n",
      "tensor(31.6042, grad_fn=<NllLossBackward>)\n",
      "tensor(38.6577, grad_fn=<NllLossBackward>)\n",
      "tensor(42.0210, grad_fn=<NllLossBackward>)\n",
      "tensor(36.1712, grad_fn=<NllLossBackward>)\n",
      "tensor(31.3319, grad_fn=<NllLossBackward>)\n",
      "tensor(31.2266, grad_fn=<NllLossBackward>)\n",
      "tensor(34.0985, grad_fn=<NllLossBackward>)\n",
      "tensor(44.8007, grad_fn=<NllLossBackward>)\n",
      "tensor(52.6961, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â                                     | 272/10000 [00:01<00:56, 171.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.1043, grad_fn=<NllLossBackward>)\n",
      "tensor(51.0304, grad_fn=<NllLossBackward>)\n",
      "tensor(47.5919, grad_fn=<NllLossBackward>)\n",
      "tensor(48.2453, grad_fn=<NllLossBackward>)\n",
      "tensor(50.1742, grad_fn=<NllLossBackward>)\n",
      "tensor(47.9248, grad_fn=<NllLossBackward>)\n",
      "tensor(42.9480, grad_fn=<NllLossBackward>)\n",
      "tensor(40.4051, grad_fn=<NllLossBackward>)\n",
      "tensor(41.2752, grad_fn=<NllLossBackward>)\n",
      "tensor(49.4338, grad_fn=<NllLossBackward>)\n",
      "tensor(43.5715, grad_fn=<NllLossBackward>)\n",
      "tensor(42.0312, grad_fn=<NllLossBackward>)\n",
      "tensor(43.8151, grad_fn=<NllLossBackward>)\n",
      "tensor(41.6295, grad_fn=<NllLossBackward>)\n",
      "tensor(46.0252, grad_fn=<NllLossBackward>)\n",
      "tensor(44.1641, grad_fn=<NllLossBackward>)\n",
      "tensor(46.5077, grad_fn=<NllLossBackward>)\n",
      "tensor(42.6289, grad_fn=<NllLossBackward>)\n",
      "tensor(42.1005, grad_fn=<NllLossBackward>)\n",
      "tensor(41.5434, grad_fn=<NllLossBackward>)\n",
      "tensor(46.7957, grad_fn=<NllLossBackward>)\n",
      "tensor(33.5645, grad_fn=<NllLossBackward>)\n",
      "tensor(25.8137, grad_fn=<NllLossBackward>)\n",
      "tensor(22.2768, grad_fn=<NllLossBackward>)\n",
      "tensor(28.1527, grad_fn=<NllLossBackward>)\n",
      "tensor(31.5498, grad_fn=<NllLossBackward>)\n",
      "tensor(31.1875, grad_fn=<NllLossBackward>)\n",
      "tensor(38.0137, grad_fn=<NllLossBackward>)\n",
      "tensor(41.4153, grad_fn=<NllLossBackward>)\n",
      "tensor(47.0488, grad_fn=<NllLossBackward>)\n",
      "tensor(35.0689, grad_fn=<NllLossBackward>)\n",
      "tensor(26.0348, grad_fn=<NllLossBackward>)\n",
      "tensor(28.1298, grad_fn=<NllLossBackward>)\n",
      "tensor(33.3550, grad_fn=<NllLossBackward>)\n",
      "tensor(29.8283, grad_fn=<NllLossBackward>)\n",
      "tensor(29.9672, grad_fn=<NllLossBackward>)\n",
      "tensor(38.6951, grad_fn=<NllLossBackward>)\n",
      "tensor(36.2898, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|ââ                                    | 311/10000 [00:01<00:53, 180.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.3440, grad_fn=<NllLossBackward>)\n",
      "tensor(34.3052, grad_fn=<NllLossBackward>)\n",
      "tensor(41.6934, grad_fn=<NllLossBackward>)\n",
      "tensor(32.7888, grad_fn=<NllLossBackward>)\n",
      "tensor(31.8298, grad_fn=<NllLossBackward>)\n",
      "tensor(29.0394, grad_fn=<NllLossBackward>)\n",
      "tensor(36.7652, grad_fn=<NllLossBackward>)\n",
      "tensor(32.8520, grad_fn=<NllLossBackward>)\n",
      "tensor(28.4014, grad_fn=<NllLossBackward>)\n",
      "tensor(27.1083, grad_fn=<NllLossBackward>)\n",
      "tensor(29.5537, grad_fn=<NllLossBackward>)\n",
      "tensor(31.7525, grad_fn=<NllLossBackward>)\n",
      "tensor(41.1369, grad_fn=<NllLossBackward>)\n",
      "tensor(49.5216, grad_fn=<NllLossBackward>)\n",
      "tensor(44.4264, grad_fn=<NllLossBackward>)\n",
      "tensor(36.2255, grad_fn=<NllLossBackward>)\n",
      "tensor(34.8016, grad_fn=<NllLossBackward>)\n",
      "tensor(38.7667, grad_fn=<NllLossBackward>)\n",
      "tensor(38.8983, grad_fn=<NllLossBackward>)\n",
      "tensor(43.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(35.7802, grad_fn=<NllLossBackward>)\n",
      "tensor(32.7859, grad_fn=<NllLossBackward>)\n",
      "tensor(35.7428, grad_fn=<NllLossBackward>)\n",
      "tensor(34.5880, grad_fn=<NllLossBackward>)\n",
      "tensor(30.6911, grad_fn=<NllLossBackward>)\n",
      "tensor(30.9341, grad_fn=<NllLossBackward>)\n",
      "tensor(23.7578, grad_fn=<NllLossBackward>)\n",
      "tensor(21.9262, grad_fn=<NllLossBackward>)\n",
      "tensor(26.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(25.4307, grad_fn=<NllLossBackward>)\n",
      "tensor(24.5181, grad_fn=<NllLossBackward>)\n",
      "tensor(25.9132, grad_fn=<NllLossBackward>)\n",
      "tensor(27.8627, grad_fn=<NllLossBackward>)\n",
      "tensor(27.4937, grad_fn=<NllLossBackward>)\n",
      "tensor(25.7652, grad_fn=<NllLossBackward>)\n",
      "tensor(25.2794, grad_fn=<NllLossBackward>)\n",
      "tensor(23.5046, grad_fn=<NllLossBackward>)\n",
      "tensor(25.5060, grad_fn=<NllLossBackward>)\n",
      "tensor(32.5826, grad_fn=<NllLossBackward>)\n",
      "tensor(41.2528, grad_fn=<NllLossBackward>)\n",
      "tensor(31.7239, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|ââ                                    | 356/10000 [00:02<00:48, 198.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.2482, grad_fn=<NllLossBackward>)\n",
      "tensor(20.7821, grad_fn=<NllLossBackward>)\n",
      "tensor(18.4101, grad_fn=<NllLossBackward>)\n",
      "tensor(19.0672, grad_fn=<NllLossBackward>)\n",
      "tensor(26.4484, grad_fn=<NllLossBackward>)\n",
      "tensor(21.5540, grad_fn=<NllLossBackward>)\n",
      "tensor(18.5131, grad_fn=<NllLossBackward>)\n",
      "tensor(23.6731, grad_fn=<NllLossBackward>)\n",
      "tensor(31.1353, grad_fn=<NllLossBackward>)\n",
      "tensor(33.9134, grad_fn=<NllLossBackward>)\n",
      "tensor(23.2712, grad_fn=<NllLossBackward>)\n",
      "tensor(23.9978, grad_fn=<NllLossBackward>)\n",
      "tensor(28.7829, grad_fn=<NllLossBackward>)\n",
      "tensor(29.3701, grad_fn=<NllLossBackward>)\n",
      "tensor(39.0363, grad_fn=<NllLossBackward>)\n",
      "tensor(30.7545, grad_fn=<NllLossBackward>)\n",
      "tensor(30.5104, grad_fn=<NllLossBackward>)\n",
      "tensor(26.6676, grad_fn=<NllLossBackward>)\n",
      "tensor(28.6258, grad_fn=<NllLossBackward>)\n",
      "tensor(30.8431, grad_fn=<NllLossBackward>)\n",
      "tensor(39.5195, grad_fn=<NllLossBackward>)\n",
      "tensor(37.5829, grad_fn=<NllLossBackward>)\n",
      "tensor(25.8607, grad_fn=<NllLossBackward>)\n",
      "tensor(25.1644, grad_fn=<NllLossBackward>)\n",
      "tensor(26.0330, grad_fn=<NllLossBackward>)\n",
      "tensor(28.6855, grad_fn=<NllLossBackward>)\n",
      "tensor(31.2534, grad_fn=<NllLossBackward>)\n",
      "tensor(35.3913, grad_fn=<NllLossBackward>)\n",
      "tensor(34.2778, grad_fn=<NllLossBackward>)\n",
      "tensor(31.1758, grad_fn=<NllLossBackward>)\n",
      "tensor(28.1026, grad_fn=<NllLossBackward>)\n",
      "tensor(29.4959, grad_fn=<NllLossBackward>)\n",
      "tensor(34.5431, grad_fn=<NllLossBackward>)\n",
      "tensor(37.0129, grad_fn=<NllLossBackward>)\n",
      "tensor(34.9979, grad_fn=<NllLossBackward>)\n",
      "tensor(31.8772, grad_fn=<NllLossBackward>)\n",
      "tensor(34.9211, grad_fn=<NllLossBackward>)\n",
      "tensor(40.0870, grad_fn=<NllLossBackward>)\n",
      "tensor(34.6367, grad_fn=<NllLossBackward>)\n",
      "tensor(37.9455, grad_fn=<NllLossBackward>)\n",
      "tensor(39.6664, grad_fn=<NllLossBackward>)\n",
      "tensor(32.8153, grad_fn=<NllLossBackward>)\n",
      "tensor(24.1710, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|ââ                                    | 398/10000 [00:02<00:48, 199.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.8140, grad_fn=<NllLossBackward>)\n",
      "tensor(32.3696, grad_fn=<NllLossBackward>)\n",
      "tensor(32.9281, grad_fn=<NllLossBackward>)\n",
      "tensor(30.0932, grad_fn=<NllLossBackward>)\n",
      "tensor(28.1913, grad_fn=<NllLossBackward>)\n",
      "tensor(27.7977, grad_fn=<NllLossBackward>)\n",
      "tensor(35.3281, grad_fn=<NllLossBackward>)\n",
      "tensor(37.0181, grad_fn=<NllLossBackward>)\n",
      "tensor(35.1863, grad_fn=<NllLossBackward>)\n",
      "tensor(40.2278, grad_fn=<NllLossBackward>)\n",
      "tensor(41.2519, grad_fn=<NllLossBackward>)\n",
      "tensor(41.4733, grad_fn=<NllLossBackward>)\n",
      "tensor(42.6384, grad_fn=<NllLossBackward>)\n",
      "tensor(39.2599, grad_fn=<NllLossBackward>)\n",
      "tensor(33.4825, grad_fn=<NllLossBackward>)\n",
      "tensor(33.7210, grad_fn=<NllLossBackward>)\n",
      "tensor(29.6545, grad_fn=<NllLossBackward>)\n",
      "tensor(23.6050, grad_fn=<NllLossBackward>)\n",
      "tensor(25.1372, grad_fn=<NllLossBackward>)\n",
      "tensor(21.1824, grad_fn=<NllLossBackward>)\n",
      "tensor(21.2849, grad_fn=<NllLossBackward>)\n",
      "tensor(27.0632, grad_fn=<NllLossBackward>)\n",
      "tensor(24.8397, grad_fn=<NllLossBackward>)\n",
      "tensor(24.5283, grad_fn=<NllLossBackward>)\n",
      "tensor(33.6225, grad_fn=<NllLossBackward>)\n",
      "tensor(32.3562, grad_fn=<NllLossBackward>)\n",
      "tensor(27.4805, grad_fn=<NllLossBackward>)\n",
      "tensor(30.6861, grad_fn=<NllLossBackward>)\n",
      "tensor(36.6807, grad_fn=<NllLossBackward>)\n",
      "tensor(35.9629, grad_fn=<NllLossBackward>)\n",
      "tensor(34.0033, grad_fn=<NllLossBackward>)\n",
      "tensor(31.3442, grad_fn=<NllLossBackward>)\n",
      "tensor(33.6537, grad_fn=<NllLossBackward>)\n",
      "tensor(25.5475, grad_fn=<NllLossBackward>)\n",
      "tensor(23.4082, grad_fn=<NllLossBackward>)\n",
      "tensor(27.6901, grad_fn=<NllLossBackward>)\n",
      "tensor(30.1204, grad_fn=<NllLossBackward>)\n",
      "tensor(27.2271, grad_fn=<NllLossBackward>)\n",
      "tensor(28.9707, grad_fn=<NllLossBackward>)\n",
      "tensor(26.6564, grad_fn=<NllLossBackward>)\n",
      "tensor(27.1897, grad_fn=<NllLossBackward>)\n",
      "tensor(33.8811, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|ââ                                    | 443/10000 [00:02<00:45, 211.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30.2998, grad_fn=<NllLossBackward>)\n",
      "tensor(19.0175, grad_fn=<NllLossBackward>)\n",
      "tensor(20.2811, grad_fn=<NllLossBackward>)\n",
      "tensor(19.5631, grad_fn=<NllLossBackward>)\n",
      "tensor(23.2953, grad_fn=<NllLossBackward>)\n",
      "tensor(27.3441, grad_fn=<NllLossBackward>)\n",
      "tensor(25.5502, grad_fn=<NllLossBackward>)\n",
      "tensor(29.7902, grad_fn=<NllLossBackward>)\n",
      "tensor(31.0408, grad_fn=<NllLossBackward>)\n",
      "tensor(28.6651, grad_fn=<NllLossBackward>)\n",
      "tensor(30.9469, grad_fn=<NllLossBackward>)\n",
      "tensor(20.8870, grad_fn=<NllLossBackward>)\n",
      "tensor(14.5179, grad_fn=<NllLossBackward>)\n",
      "tensor(15.9755, grad_fn=<NllLossBackward>)\n",
      "tensor(19.3541, grad_fn=<NllLossBackward>)\n",
      "tensor(21.7950, grad_fn=<NllLossBackward>)\n",
      "tensor(23.9720, grad_fn=<NllLossBackward>)\n",
      "tensor(31.4581, grad_fn=<NllLossBackward>)\n",
      "tensor(26.4962, grad_fn=<NllLossBackward>)\n",
      "tensor(27.4506, grad_fn=<NllLossBackward>)\n",
      "tensor(26.1144, grad_fn=<NllLossBackward>)\n",
      "tensor(30.2818, grad_fn=<NllLossBackward>)\n",
      "tensor(27.8883, grad_fn=<NllLossBackward>)\n",
      "tensor(25.2111, grad_fn=<NllLossBackward>)\n",
      "tensor(24.5396, grad_fn=<NllLossBackward>)\n",
      "tensor(25.4772, grad_fn=<NllLossBackward>)\n",
      "tensor(23.6713, grad_fn=<NllLossBackward>)\n",
      "tensor(22.2803, grad_fn=<NllLossBackward>)\n",
      "tensor(17.5530, grad_fn=<NllLossBackward>)\n",
      "tensor(18.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(17.3986, grad_fn=<NllLossBackward>)\n",
      "tensor(16.8407, grad_fn=<NllLossBackward>)\n",
      "tensor(23.5991, grad_fn=<NllLossBackward>)\n",
      "tensor(30.5925, grad_fn=<NllLossBackward>)\n",
      "tensor(36.2819, grad_fn=<NllLossBackward>)\n",
      "tensor(28.8118, grad_fn=<NllLossBackward>)\n",
      "tensor(29.1396, grad_fn=<NllLossBackward>)\n",
      "tensor(33.8337, grad_fn=<NllLossBackward>)\n",
      "tensor(29.4875, grad_fn=<NllLossBackward>)\n",
      "tensor(22.5042, grad_fn=<NllLossBackward>)\n",
      "tensor(17.4153, grad_fn=<NllLossBackward>)\n",
      "tensor(18.8400, grad_fn=<NllLossBackward>)\n",
      "tensor(30.4291, grad_fn=<NllLossBackward>)\n",
      "tensor(27.3567, grad_fn=<NllLossBackward>)\n",
      "tensor(25.5678, grad_fn=<NllLossBackward>)\n",
      "tensor(28.5089, grad_fn=<NllLossBackward>)\n",
      "tensor(27.4715, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|ââ                                    | 491/10000 [00:02<00:42, 221.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.0547, grad_fn=<NllLossBackward>)\n",
      "tensor(16.2274, grad_fn=<NllLossBackward>)\n",
      "tensor(13.6349, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9755, grad_fn=<NllLossBackward>)\n",
      "tensor(16.6913, grad_fn=<NllLossBackward>)\n",
      "tensor(12.4821, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7410, grad_fn=<NllLossBackward>)\n",
      "tensor(13.8812, grad_fn=<NllLossBackward>)\n",
      "tensor(20.5190, grad_fn=<NllLossBackward>)\n",
      "tensor(26.5631, grad_fn=<NllLossBackward>)\n",
      "tensor(25.9230, grad_fn=<NllLossBackward>)\n",
      "tensor(23.0268, grad_fn=<NllLossBackward>)\n",
      "tensor(20.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(21.6620, grad_fn=<NllLossBackward>)\n",
      "tensor(27.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(23.9881, grad_fn=<NllLossBackward>)\n",
      "tensor(24.3598, grad_fn=<NllLossBackward>)\n",
      "tensor(28.8189, grad_fn=<NllLossBackward>)\n",
      "tensor(31.5740, grad_fn=<NllLossBackward>)\n",
      "tensor(24.0567, grad_fn=<NllLossBackward>)\n",
      "tensor(24.1374, grad_fn=<NllLossBackward>)\n",
      "tensor(24.4858, grad_fn=<NllLossBackward>)\n",
      "tensor(24.7498, grad_fn=<NllLossBackward>)\n",
      "tensor(25.0352, grad_fn=<NllLossBackward>)\n",
      "tensor(31.9502, grad_fn=<NllLossBackward>)\n",
      "tensor(32.2165, grad_fn=<NllLossBackward>)\n",
      "tensor(27.8985, grad_fn=<NllLossBackward>)\n",
      "tensor(23.4002, grad_fn=<NllLossBackward>)\n",
      "tensor(22.4729, grad_fn=<NllLossBackward>)\n",
      "tensor(25.1613, grad_fn=<NllLossBackward>)\n",
      "tensor(24.2573, grad_fn=<NllLossBackward>)\n",
      "tensor(24.7327, grad_fn=<NllLossBackward>)\n",
      "tensor(26.8542, grad_fn=<NllLossBackward>)\n",
      "tensor(22.1965, grad_fn=<NllLossBackward>)\n",
      "tensor(25.9363, grad_fn=<NllLossBackward>)\n",
      "tensor(27.6742, grad_fn=<NllLossBackward>)\n",
      "tensor(19.9549, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4527, grad_fn=<NllLossBackward>)\n",
      "tensor(17.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(16.0110, grad_fn=<NllLossBackward>)\n",
      "tensor(22.1341, grad_fn=<NllLossBackward>)\n",
      "tensor(31.0747, grad_fn=<NllLossBackward>)\n",
      "tensor(22.3588, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9908, grad_fn=<NllLossBackward>)\n",
      "tensor(19.0928, grad_fn=<NllLossBackward>)\n",
      "tensor(24.4568, grad_fn=<NllLossBackward>)\n",
      "tensor(24.6571, grad_fn=<NllLossBackward>)\n",
      "tensor(24.8905, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|ââ                                    | 537/10000 [00:03<00:42, 220.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23.2988, grad_fn=<NllLossBackward>)\n",
      "tensor(26.2389, grad_fn=<NllLossBackward>)\n",
      "tensor(28.4033, grad_fn=<NllLossBackward>)\n",
      "tensor(21.2182, grad_fn=<NllLossBackward>)\n",
      "tensor(19.7582, grad_fn=<NllLossBackward>)\n",
      "tensor(19.6907, grad_fn=<NllLossBackward>)\n",
      "tensor(19.1931, grad_fn=<NllLossBackward>)\n",
      "tensor(21.4726, grad_fn=<NllLossBackward>)\n",
      "tensor(23.5640, grad_fn=<NllLossBackward>)\n",
      "tensor(21.1493, grad_fn=<NllLossBackward>)\n",
      "tensor(21.4801, grad_fn=<NllLossBackward>)\n",
      "tensor(15.7003, grad_fn=<NllLossBackward>)\n",
      "tensor(20.4195, grad_fn=<NllLossBackward>)\n",
      "tensor(29.5216, grad_fn=<NllLossBackward>)\n",
      "tensor(26.1855, grad_fn=<NllLossBackward>)\n",
      "tensor(25.4924, grad_fn=<NllLossBackward>)\n",
      "tensor(27.5127, grad_fn=<NllLossBackward>)\n",
      "tensor(21.4190, grad_fn=<NllLossBackward>)\n",
      "tensor(21.0947, grad_fn=<NllLossBackward>)\n",
      "tensor(23.9281, grad_fn=<NllLossBackward>)\n",
      "tensor(18.4949, grad_fn=<NllLossBackward>)\n",
      "tensor(17.1240, grad_fn=<NllLossBackward>)\n",
      "tensor(23.5970, grad_fn=<NllLossBackward>)\n",
      "tensor(28.7255, grad_fn=<NllLossBackward>)\n",
      "tensor(24.8467, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2551, grad_fn=<NllLossBackward>)\n",
      "tensor(16.3715, grad_fn=<NllLossBackward>)\n",
      "tensor(27.6340, grad_fn=<NllLossBackward>)\n",
      "tensor(28.1304, grad_fn=<NllLossBackward>)\n",
      "tensor(31.3454, grad_fn=<NllLossBackward>)\n",
      "tensor(31.3235, grad_fn=<NllLossBackward>)\n",
      "tensor(27.8384, grad_fn=<NllLossBackward>)\n",
      "tensor(20.6918, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5381, grad_fn=<NllLossBackward>)\n",
      "tensor(18.1796, grad_fn=<NllLossBackward>)\n",
      "tensor(25.9020, grad_fn=<NllLossBackward>)\n",
      "tensor(31.2909, grad_fn=<NllLossBackward>)\n",
      "tensor(31.2159, grad_fn=<NllLossBackward>)\n",
      "tensor(26.1986, grad_fn=<NllLossBackward>)\n",
      "tensor(27.1296, grad_fn=<NllLossBackward>)\n",
      "tensor(24.9557, grad_fn=<NllLossBackward>)\n",
      "tensor(23.0197, grad_fn=<NllLossBackward>)\n",
      "tensor(32.0806, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|âââ                                   | 582/10000 [00:03<00:44, 211.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(31.3673, grad_fn=<NllLossBackward>)\n",
      "tensor(23.4609, grad_fn=<NllLossBackward>)\n",
      "tensor(22.2212, grad_fn=<NllLossBackward>)\n",
      "tensor(25.4360, grad_fn=<NllLossBackward>)\n",
      "tensor(24.8416, grad_fn=<NllLossBackward>)\n",
      "tensor(27.4413, grad_fn=<NllLossBackward>)\n",
      "tensor(26.2849, grad_fn=<NllLossBackward>)\n",
      "tensor(21.4456, grad_fn=<NllLossBackward>)\n",
      "tensor(18.4216, grad_fn=<NllLossBackward>)\n",
      "tensor(19.4005, grad_fn=<NllLossBackward>)\n",
      "tensor(23.5801, grad_fn=<NllLossBackward>)\n",
      "tensor(23.9372, grad_fn=<NllLossBackward>)\n",
      "tensor(30.0389, grad_fn=<NllLossBackward>)\n",
      "tensor(36.9053, grad_fn=<NllLossBackward>)\n",
      "tensor(32.4094, grad_fn=<NllLossBackward>)\n",
      "tensor(21.9567, grad_fn=<NllLossBackward>)\n",
      "tensor(19.2603, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7406, grad_fn=<NllLossBackward>)\n",
      "tensor(25.6223, grad_fn=<NllLossBackward>)\n",
      "tensor(26.7228, grad_fn=<NllLossBackward>)\n",
      "tensor(25.7401, grad_fn=<NllLossBackward>)\n",
      "tensor(20.5810, grad_fn=<NllLossBackward>)\n",
      "tensor(17.0487, grad_fn=<NllLossBackward>)\n",
      "tensor(20.1507, grad_fn=<NllLossBackward>)\n",
      "tensor(24.4502, grad_fn=<NllLossBackward>)\n",
      "tensor(19.5522, grad_fn=<NllLossBackward>)\n",
      "tensor(19.1200, grad_fn=<NllLossBackward>)\n",
      "tensor(20.0427, grad_fn=<NllLossBackward>)\n",
      "tensor(21.1692, grad_fn=<NllLossBackward>)\n",
      "tensor(25.1832, grad_fn=<NllLossBackward>)\n",
      "tensor(21.1146, grad_fn=<NllLossBackward>)\n",
      "tensor(20.4550, grad_fn=<NllLossBackward>)\n",
      "tensor(27.8691, grad_fn=<NllLossBackward>)\n",
      "tensor(23.6818, grad_fn=<NllLossBackward>)\n",
      "tensor(18.0211, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9587, grad_fn=<NllLossBackward>)\n",
      "tensor(13.0170, grad_fn=<NllLossBackward>)\n",
      "tensor(21.9390, grad_fn=<NllLossBackward>)\n",
      "tensor(30.9559, grad_fn=<NllLossBackward>)\n",
      "tensor(24.0696, grad_fn=<NllLossBackward>)\n",
      "tensor(17.9900, grad_fn=<NllLossBackward>)\n",
      "tensor(17.3459, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|âââ                                   | 630/10000 [00:03<00:42, 221.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.9560, grad_fn=<NllLossBackward>)\n",
      "tensor(16.8843, grad_fn=<NllLossBackward>)\n",
      "tensor(15.3242, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5949, grad_fn=<NllLossBackward>)\n",
      "tensor(13.4687, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8797, grad_fn=<NllLossBackward>)\n",
      "tensor(15.1562, grad_fn=<NllLossBackward>)\n",
      "tensor(17.8344, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5591, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9278, grad_fn=<NllLossBackward>)\n",
      "tensor(20.1207, grad_fn=<NllLossBackward>)\n",
      "tensor(19.0817, grad_fn=<NllLossBackward>)\n",
      "tensor(18.0450, grad_fn=<NllLossBackward>)\n",
      "tensor(20.9126, grad_fn=<NllLossBackward>)\n",
      "tensor(22.2802, grad_fn=<NllLossBackward>)\n",
      "tensor(19.2445, grad_fn=<NllLossBackward>)\n",
      "tensor(20.7257, grad_fn=<NllLossBackward>)\n",
      "tensor(23.6025, grad_fn=<NllLossBackward>)\n",
      "tensor(23.3802, grad_fn=<NllLossBackward>)\n",
      "tensor(21.3040, grad_fn=<NllLossBackward>)\n",
      "tensor(28.5521, grad_fn=<NllLossBackward>)\n",
      "tensor(25.1414, grad_fn=<NllLossBackward>)\n",
      "tensor(20.5355, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4278, grad_fn=<NllLossBackward>)\n",
      "tensor(18.6801, grad_fn=<NllLossBackward>)\n",
      "tensor(16.9895, grad_fn=<NllLossBackward>)\n",
      "tensor(19.5891, grad_fn=<NllLossBackward>)\n",
      "tensor(22.4333, grad_fn=<NllLossBackward>)\n",
      "tensor(19.3505, grad_fn=<NllLossBackward>)\n",
      "tensor(22.3896, grad_fn=<NllLossBackward>)\n",
      "tensor(20.7165, grad_fn=<NllLossBackward>)\n",
      "tensor(28.7358, grad_fn=<NllLossBackward>)\n",
      "tensor(29.3405, grad_fn=<NllLossBackward>)\n",
      "tensor(26.3131, grad_fn=<NllLossBackward>)\n",
      "tensor(18.2747, grad_fn=<NllLossBackward>)\n",
      "tensor(14.6827, grad_fn=<NllLossBackward>)\n",
      "tensor(17.8892, grad_fn=<NllLossBackward>)\n",
      "tensor(17.7152, grad_fn=<NllLossBackward>)\n",
      "tensor(24.7530, grad_fn=<NllLossBackward>)\n",
      "tensor(24.6562, grad_fn=<NllLossBackward>)\n",
      "tensor(21.2808, grad_fn=<NllLossBackward>)\n",
      "tensor(13.8072, grad_fn=<NllLossBackward>)\n",
      "tensor(15.0488, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4024, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7976, grad_fn=<NllLossBackward>)\n",
      "tensor(16.1166, grad_fn=<NllLossBackward>)\n",
      "tensor(13.7917, grad_fn=<NllLossBackward>)\n",
      "tensor(14.7624, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|âââ                                   | 679/10000 [00:03<00:40, 231.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.6994, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6417, grad_fn=<NllLossBackward>)\n",
      "tensor(11.7615, grad_fn=<NllLossBackward>)\n",
      "tensor(13.3671, grad_fn=<NllLossBackward>)\n",
      "tensor(12.7314, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9227, grad_fn=<NllLossBackward>)\n",
      "tensor(12.8148, grad_fn=<NllLossBackward>)\n",
      "tensor(16.5230, grad_fn=<NllLossBackward>)\n",
      "tensor(17.5450, grad_fn=<NllLossBackward>)\n",
      "tensor(21.7957, grad_fn=<NllLossBackward>)\n",
      "tensor(23.6790, grad_fn=<NllLossBackward>)\n",
      "tensor(18.6235, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1281, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2480, grad_fn=<NllLossBackward>)\n",
      "tensor(19.6781, grad_fn=<NllLossBackward>)\n",
      "tensor(14.7733, grad_fn=<NllLossBackward>)\n",
      "tensor(17.1795, grad_fn=<NllLossBackward>)\n",
      "tensor(17.4090, grad_fn=<NllLossBackward>)\n",
      "tensor(21.7540, grad_fn=<NllLossBackward>)\n",
      "tensor(28.5044, grad_fn=<NllLossBackward>)\n",
      "tensor(24.7200, grad_fn=<NllLossBackward>)\n",
      "tensor(21.2717, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4805, grad_fn=<NllLossBackward>)\n",
      "tensor(20.1994, grad_fn=<NllLossBackward>)\n",
      "tensor(27.2258, grad_fn=<NllLossBackward>)\n",
      "tensor(20.0486, grad_fn=<NllLossBackward>)\n",
      "tensor(13.4421, grad_fn=<NllLossBackward>)\n",
      "tensor(13.0687, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6128, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4636, grad_fn=<NllLossBackward>)\n",
      "tensor(11.4717, grad_fn=<NllLossBackward>)\n",
      "tensor(17.6386, grad_fn=<NllLossBackward>)\n",
      "tensor(20.7007, grad_fn=<NllLossBackward>)\n",
      "tensor(20.5052, grad_fn=<NllLossBackward>)\n",
      "tensor(20.4595, grad_fn=<NllLossBackward>)\n",
      "tensor(16.3422, grad_fn=<NllLossBackward>)\n",
      "tensor(15.4228, grad_fn=<NllLossBackward>)\n",
      "tensor(20.0500, grad_fn=<NllLossBackward>)\n",
      "tensor(16.8059, grad_fn=<NllLossBackward>)\n",
      "tensor(20.8602, grad_fn=<NllLossBackward>)\n",
      "tensor(14.1138, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7585, grad_fn=<NllLossBackward>)\n",
      "tensor(8.0543, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6949, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6824, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0725, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2169, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6091, grad_fn=<NllLossBackward>)\n",
      "tensor(9.0127, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|âââ                                   | 731/10000 [00:03<00:38, 243.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.9611, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9852, grad_fn=<NllLossBackward>)\n",
      "tensor(13.4850, grad_fn=<NllLossBackward>)\n",
      "tensor(9.4060, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9125, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7576, grad_fn=<NllLossBackward>)\n",
      "tensor(14.3744, grad_fn=<NllLossBackward>)\n",
      "tensor(16.5921, grad_fn=<NllLossBackward>)\n",
      "tensor(18.0937, grad_fn=<NllLossBackward>)\n",
      "tensor(19.7227, grad_fn=<NllLossBackward>)\n",
      "tensor(28.3240, grad_fn=<NllLossBackward>)\n",
      "tensor(34.2341, grad_fn=<NllLossBackward>)\n",
      "tensor(29.3057, grad_fn=<NllLossBackward>)\n",
      "tensor(20.8748, grad_fn=<NllLossBackward>)\n",
      "tensor(20.3009, grad_fn=<NllLossBackward>)\n",
      "tensor(25.0538, grad_fn=<NllLossBackward>)\n",
      "tensor(22.8096, grad_fn=<NllLossBackward>)\n",
      "tensor(19.9387, grad_fn=<NllLossBackward>)\n",
      "tensor(18.2137, grad_fn=<NllLossBackward>)\n",
      "tensor(19.0512, grad_fn=<NllLossBackward>)\n",
      "tensor(17.1016, grad_fn=<NllLossBackward>)\n",
      "tensor(15.5906, grad_fn=<NllLossBackward>)\n",
      "tensor(13.0991, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0356, grad_fn=<NllLossBackward>)\n",
      "tensor(13.2778, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6750, grad_fn=<NllLossBackward>)\n",
      "tensor(13.1536, grad_fn=<NllLossBackward>)\n",
      "tensor(13.7107, grad_fn=<NllLossBackward>)\n",
      "tensor(16.6820, grad_fn=<NllLossBackward>)\n",
      "tensor(12.4142, grad_fn=<NllLossBackward>)\n",
      "tensor(13.8799, grad_fn=<NllLossBackward>)\n",
      "tensor(15.8943, grad_fn=<NllLossBackward>)\n",
      "tensor(16.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(22.3213, grad_fn=<NllLossBackward>)\n",
      "tensor(19.3498, grad_fn=<NllLossBackward>)\n",
      "tensor(14.8685, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9354, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6250, grad_fn=<NllLossBackward>)\n",
      "tensor(12.7008, grad_fn=<NllLossBackward>)\n",
      "tensor(19.2800, grad_fn=<NllLossBackward>)\n",
      "tensor(17.5755, grad_fn=<NllLossBackward>)\n",
      "tensor(15.8933, grad_fn=<NllLossBackward>)\n",
      "tensor(18.4363, grad_fn=<NllLossBackward>)\n",
      "tensor(17.1804, grad_fn=<NllLossBackward>)\n",
      "tensor(17.2202, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5863, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9544, grad_fn=<NllLossBackward>)\n",
      "tensor(15.7879, grad_fn=<NllLossBackward>)\n",
      "tensor(15.5928, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7258, grad_fn=<NllLossBackward>)\n",
      "tensor(14.9791, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7174, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|âââ                                   | 784/10000 [00:04<00:36, 251.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.6279, grad_fn=<NllLossBackward>)\n",
      "tensor(19.4297, grad_fn=<NllLossBackward>)\n",
      "tensor(19.3943, grad_fn=<NllLossBackward>)\n",
      "tensor(17.5132, grad_fn=<NllLossBackward>)\n",
      "tensor(18.8828, grad_fn=<NllLossBackward>)\n",
      "tensor(15.8416, grad_fn=<NllLossBackward>)\n",
      "tensor(13.2722, grad_fn=<NllLossBackward>)\n",
      "tensor(17.7960, grad_fn=<NllLossBackward>)\n",
      "tensor(16.0733, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0902, grad_fn=<NllLossBackward>)\n",
      "tensor(14.0659, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7979, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9298, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2835, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5060, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7084, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9911, grad_fn=<NllLossBackward>)\n",
      "tensor(22.3711, grad_fn=<NllLossBackward>)\n",
      "tensor(27.0143, grad_fn=<NllLossBackward>)\n",
      "tensor(20.9928, grad_fn=<NllLossBackward>)\n",
      "tensor(19.8610, grad_fn=<NllLossBackward>)\n",
      "tensor(16.2208, grad_fn=<NllLossBackward>)\n",
      "tensor(20.9140, grad_fn=<NllLossBackward>)\n",
      "tensor(24.6467, grad_fn=<NllLossBackward>)\n",
      "tensor(21.0004, grad_fn=<NllLossBackward>)\n",
      "tensor(17.9131, grad_fn=<NllLossBackward>)\n",
      "tensor(19.6638, grad_fn=<NllLossBackward>)\n",
      "tensor(22.1317, grad_fn=<NllLossBackward>)\n",
      "tensor(22.9861, grad_fn=<NllLossBackward>)\n",
      "tensor(19.2221, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4208, grad_fn=<NllLossBackward>)\n",
      "tensor(19.4793, grad_fn=<NllLossBackward>)\n",
      "tensor(19.8329, grad_fn=<NllLossBackward>)\n",
      "tensor(21.7101, grad_fn=<NllLossBackward>)\n",
      "tensor(22.6048, grad_fn=<NllLossBackward>)\n",
      "tensor(18.5577, grad_fn=<NllLossBackward>)\n",
      "tensor(20.2091, grad_fn=<NllLossBackward>)\n",
      "tensor(14.6573, grad_fn=<NllLossBackward>)\n",
      "tensor(16.0369, grad_fn=<NllLossBackward>)\n",
      "tensor(25.2999, grad_fn=<NllLossBackward>)\n",
      "tensor(23.1415, grad_fn=<NllLossBackward>)\n",
      "tensor(18.5775, grad_fn=<NllLossBackward>)\n",
      "tensor(13.2793, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6128, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6581, grad_fn=<NllLossBackward>)\n",
      "tensor(15.1281, grad_fn=<NllLossBackward>)\n",
      "tensor(18.3612, grad_fn=<NllLossBackward>)\n",
      "tensor(17.9516, grad_fn=<NllLossBackward>)\n",
      "tensor(15.8067, grad_fn=<NllLossBackward>)\n",
      "tensor(15.1462, grad_fn=<NllLossBackward>)\n",
      "tensor(8.5744, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6260, grad_fn=<NllLossBackward>)\n",
      "tensor(7.1471, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|ââââ                                  | 839/10000 [00:04<00:35, 259.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5082, grad_fn=<NllLossBackward>)\n",
      "tensor(11.8908, grad_fn=<NllLossBackward>)\n",
      "tensor(14.1539, grad_fn=<NllLossBackward>)\n",
      "tensor(11.4274, grad_fn=<NllLossBackward>)\n",
      "tensor(9.1611, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2227, grad_fn=<NllLossBackward>)\n",
      "tensor(9.5128, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3907, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9384, grad_fn=<NllLossBackward>)\n",
      "tensor(15.6795, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4819, grad_fn=<NllLossBackward>)\n",
      "tensor(12.4244, grad_fn=<NllLossBackward>)\n",
      "tensor(14.9843, grad_fn=<NllLossBackward>)\n",
      "tensor(11.3399, grad_fn=<NllLossBackward>)\n",
      "tensor(12.7748, grad_fn=<NllLossBackward>)\n",
      "tensor(13.4003, grad_fn=<NllLossBackward>)\n",
      "tensor(11.9660, grad_fn=<NllLossBackward>)\n",
      "tensor(12.1947, grad_fn=<NllLossBackward>)\n",
      "tensor(17.1729, grad_fn=<NllLossBackward>)\n",
      "tensor(20.6243, grad_fn=<NllLossBackward>)\n",
      "tensor(17.3106, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0028, grad_fn=<NllLossBackward>)\n",
      "tensor(7.7387, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8110, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6310, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6333, grad_fn=<NllLossBackward>)\n",
      "tensor(10.5986, grad_fn=<NllLossBackward>)\n",
      "tensor(11.8691, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8139, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6798, grad_fn=<NllLossBackward>)\n",
      "tensor(14.4888, grad_fn=<NllLossBackward>)\n",
      "tensor(14.2637, grad_fn=<NllLossBackward>)\n",
      "tensor(12.7631, grad_fn=<NllLossBackward>)\n",
      "tensor(7.1973, grad_fn=<NllLossBackward>)\n",
      "tensor(6.1748, grad_fn=<NllLossBackward>)\n",
      "tensor(5.4979, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8844, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9651, grad_fn=<NllLossBackward>)\n",
      "tensor(10.5299, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8037, grad_fn=<NllLossBackward>)\n",
      "tensor(8.1644, grad_fn=<NllLossBackward>)\n",
      "tensor(11.8476, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9328, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5531, grad_fn=<NllLossBackward>)\n",
      "tensor(21.0894, grad_fn=<NllLossBackward>)\n",
      "tensor(19.7069, grad_fn=<NllLossBackward>)\n",
      "tensor(22.1383, grad_fn=<NllLossBackward>)\n",
      "tensor(19.6197, grad_fn=<NllLossBackward>)\n",
      "tensor(20.8277, grad_fn=<NllLossBackward>)\n",
      "tensor(14.8425, grad_fn=<NllLossBackward>)\n",
      "tensor(13.1938, grad_fn=<NllLossBackward>)\n",
      "tensor(23.7761, grad_fn=<NllLossBackward>)\n",
      "tensor(21.0612, grad_fn=<NllLossBackward>)\n",
      "tensor(15.7406, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|ââââ                                  | 892/10000 [00:04<00:36, 247.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.4454, grad_fn=<NllLossBackward>)\n",
      "tensor(16.9213, grad_fn=<NllLossBackward>)\n",
      "tensor(9.4933, grad_fn=<NllLossBackward>)\n",
      "tensor(7.9195, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6899, grad_fn=<NllLossBackward>)\n",
      "tensor(13.6203, grad_fn=<NllLossBackward>)\n",
      "tensor(15.4996, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6824, grad_fn=<NllLossBackward>)\n",
      "tensor(15.8796, grad_fn=<NllLossBackward>)\n",
      "tensor(21.6453, grad_fn=<NllLossBackward>)\n",
      "tensor(15.1885, grad_fn=<NllLossBackward>)\n",
      "tensor(15.9042, grad_fn=<NllLossBackward>)\n",
      "tensor(14.3230, grad_fn=<NllLossBackward>)\n",
      "tensor(13.4649, grad_fn=<NllLossBackward>)\n",
      "tensor(6.6737, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9232, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6328, grad_fn=<NllLossBackward>)\n",
      "tensor(11.9881, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8017, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5274, grad_fn=<NllLossBackward>)\n",
      "tensor(18.7257, grad_fn=<NllLossBackward>)\n",
      "tensor(23.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(18.4747, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5088, grad_fn=<NllLossBackward>)\n",
      "tensor(8.1007, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7720, grad_fn=<NllLossBackward>)\n",
      "tensor(8.6928, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7774, grad_fn=<NllLossBackward>)\n",
      "tensor(14.2841, grad_fn=<NllLossBackward>)\n",
      "tensor(15.3867, grad_fn=<NllLossBackward>)\n",
      "tensor(12.8991, grad_fn=<NllLossBackward>)\n",
      "tensor(12.3046, grad_fn=<NllLossBackward>)\n",
      "tensor(10.5628, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8092, grad_fn=<NllLossBackward>)\n",
      "tensor(13.3372, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5390, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6490, grad_fn=<NllLossBackward>)\n",
      "tensor(11.3556, grad_fn=<NllLossBackward>)\n",
      "tensor(16.1846, grad_fn=<NllLossBackward>)\n",
      "tensor(18.8790, grad_fn=<NllLossBackward>)\n",
      "tensor(17.7018, grad_fn=<NllLossBackward>)\n",
      "tensor(14.5233, grad_fn=<NllLossBackward>)\n",
      "tensor(14.8201, grad_fn=<NllLossBackward>)\n",
      "tensor(13.3243, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9732, grad_fn=<NllLossBackward>)\n",
      "tensor(14.1694, grad_fn=<NllLossBackward>)\n",
      "tensor(11.7954, grad_fn=<NllLossBackward>)\n",
      "tensor(19.7619, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|ââââ                                  | 918/10000 [00:04<00:36, 250.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.4944, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5039, grad_fn=<NllLossBackward>)\n",
      "tensor(13.0532, grad_fn=<NllLossBackward>)\n",
      "tensor(11.8610, grad_fn=<NllLossBackward>)\n",
      "tensor(13.1361, grad_fn=<NllLossBackward>)\n",
      "tensor(15.5151, grad_fn=<NllLossBackward>)\n",
      "tensor(16.0924, grad_fn=<NllLossBackward>)\n",
      "tensor(18.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9671, grad_fn=<NllLossBackward>)\n",
      "tensor(10.1165, grad_fn=<NllLossBackward>)\n",
      "tensor(13.2446, grad_fn=<NllLossBackward>)\n",
      "tensor(13.7477, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6431, grad_fn=<NllLossBackward>)\n",
      "tensor(16.3586, grad_fn=<NllLossBackward>)\n",
      "tensor(16.1891, grad_fn=<NllLossBackward>)\n",
      "tensor(17.2023, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7368, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5348, grad_fn=<NllLossBackward>)\n",
      "tensor(12.1980, grad_fn=<NllLossBackward>)\n",
      "tensor(18.5053, grad_fn=<NllLossBackward>)\n",
      "tensor(25.8674, grad_fn=<NllLossBackward>)\n",
      "tensor(18.7386, grad_fn=<NllLossBackward>)\n",
      "tensor(17.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(19.3761, grad_fn=<NllLossBackward>)\n",
      "tensor(14.7361, grad_fn=<NllLossBackward>)\n",
      "tensor(6.0109, grad_fn=<NllLossBackward>)\n",
      "tensor(8.6413, grad_fn=<NllLossBackward>)\n",
      "tensor(11.3912, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9804, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8999, grad_fn=<NllLossBackward>)\n",
      "tensor(16.3204, grad_fn=<NllLossBackward>)\n",
      "tensor(17.0959, grad_fn=<NllLossBackward>)\n",
      "tensor(16.0170, grad_fn=<NllLossBackward>)\n",
      "tensor(12.3092, grad_fn=<NllLossBackward>)\n",
      "tensor(9.5542, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6462, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6261, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5373, grad_fn=<NllLossBackward>)\n",
      "tensor(12.1262, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3018, grad_fn=<NllLossBackward>)\n",
      "tensor(12.2299, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7948, grad_fn=<NllLossBackward>)\n",
      "tensor(22.7262, grad_fn=<NllLossBackward>)\n",
      "tensor(19.2952, grad_fn=<NllLossBackward>)\n",
      "tensor(16.1979, grad_fn=<NllLossBackward>)\n",
      "tensor(14.1389, grad_fn=<NllLossBackward>)\n",
      "tensor(14.2098, grad_fn=<NllLossBackward>)\n",
      "tensor(19.4759, grad_fn=<NllLossBackward>)\n",
      "tensor(18.7820, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2918, grad_fn=<NllLossBackward>)\n",
      "tensor(12.4171, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|ââââ                                  | 969/10000 [00:04<00:36, 248.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.5364, grad_fn=<NllLossBackward>)\n",
      "tensor(11.8422, grad_fn=<NllLossBackward>)\n",
      "tensor(14.7620, grad_fn=<NllLossBackward>)\n",
      "tensor(12.8493, grad_fn=<NllLossBackward>)\n",
      "tensor(11.7337, grad_fn=<NllLossBackward>)\n",
      "tensor(15.5389, grad_fn=<NllLossBackward>)\n",
      "tensor(13.2901, grad_fn=<NllLossBackward>)\n",
      "tensor(11.7142, grad_fn=<NllLossBackward>)\n",
      "tensor(12.3991, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2634, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5388, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7948, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5058, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8332, grad_fn=<NllLossBackward>)\n",
      "tensor(16.5866, grad_fn=<NllLossBackward>)\n",
      "tensor(20.0484, grad_fn=<NllLossBackward>)\n",
      "tensor(15.5003, grad_fn=<NllLossBackward>)\n",
      "tensor(13.3471, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2571, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9812, grad_fn=<NllLossBackward>)\n",
      "tensor(11.9944, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9681, grad_fn=<NllLossBackward>)\n",
      "tensor(9.3185, grad_fn=<NllLossBackward>)\n",
      "tensor(8.5909, grad_fn=<NllLossBackward>)\n",
      "tensor(14.3754, grad_fn=<NllLossBackward>)\n",
      "tensor(15.1193, grad_fn=<NllLossBackward>)\n",
      "tensor(14.7588, grad_fn=<NllLossBackward>)\n",
      "tensor(15.3831, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5220, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9374, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7108, grad_fn=<NllLossBackward>)\n",
      "tensor(16.5053, grad_fn=<NllLossBackward>)\n",
      "tensor(17.5064, grad_fn=<NllLossBackward>)\n",
      "tensor(14.0096, grad_fn=<NllLossBackward>)\n",
      "tensor(14.4647, grad_fn=<NllLossBackward>)\n",
      "tensor(12.1944, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6091, grad_fn=<NllLossBackward>)\n",
      "tensor(6.6989, grad_fn=<NllLossBackward>)\n",
      "tensor(8.6571, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9031, grad_fn=<NllLossBackward>)\n",
      "tensor(12.3625, grad_fn=<NllLossBackward>)\n",
      "tensor(13.7172, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5031, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2207, grad_fn=<NllLossBackward>)\n",
      "tensor(8.0313, grad_fn=<NllLossBackward>)\n",
      "tensor(12.2021, grad_fn=<NllLossBackward>)\n",
      "tensor(13.6048, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8966, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5061, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4365, grad_fn=<NllLossBackward>)\n",
      "tensor(13.0975, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|ââââ                                 | 1020/10000 [00:05<00:36, 249.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5597, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6140, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7082, grad_fn=<NllLossBackward>)\n",
      "tensor(16.8114, grad_fn=<NllLossBackward>)\n",
      "tensor(15.8841, grad_fn=<NllLossBackward>)\n",
      "tensor(18.9903, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2899, grad_fn=<NllLossBackward>)\n",
      "Validation accuracy on batch 1000: 0.4965694546699524\n",
      "Training accuracy on batch 1000: 0.3476749360561371\n",
      "tensor(11.6892, grad_fn=<NllLossBackward>)\n",
      "tensor(10.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(8.2131, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7879, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0706, grad_fn=<NllLossBackward>)\n",
      "tensor(3.8290, grad_fn=<NllLossBackward>)\n",
      "tensor(5.9933, grad_fn=<NllLossBackward>)\n",
      "tensor(7.9389, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5452, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6290, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5579, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0299, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9959, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9225, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8535, grad_fn=<NllLossBackward>)\n",
      "tensor(10.1249, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0503, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6266, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6139, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5216, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9117, grad_fn=<NllLossBackward>)\n",
      "tensor(11.4404, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(14.2475, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5752, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9082, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8599, grad_fn=<NllLossBackward>)\n",
      "tensor(13.3938, grad_fn=<NllLossBackward>)\n",
      "tensor(16.7438, grad_fn=<NllLossBackward>)\n",
      "tensor(12.7976, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8094, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6986, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2854, grad_fn=<NllLossBackward>)\n",
      "tensor(7.4104, grad_fn=<NllLossBackward>)\n",
      "tensor(5.1485, grad_fn=<NllLossBackward>)\n",
      "tensor(4.3893, grad_fn=<NllLossBackward>)\n",
      "tensor(7.4591, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9088, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5256, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0273, grad_fn=<NllLossBackward>)\n",
      "tensor(7.1450, grad_fn=<NllLossBackward>)\n",
      "tensor(9.0172, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2440, grad_fn=<NllLossBackward>)\n",
      "tensor(15.4773, grad_fn=<NllLossBackward>)\n",
      "tensor(14.5239, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|ââââ                                 | 1074/10000 [00:05<00:34, 256.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.9157, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5894, grad_fn=<NllLossBackward>)\n",
      "tensor(9.1263, grad_fn=<NllLossBackward>)\n",
      "tensor(8.5817, grad_fn=<NllLossBackward>)\n",
      "tensor(13.5154, grad_fn=<NllLossBackward>)\n",
      "tensor(18.6488, grad_fn=<NllLossBackward>)\n",
      "tensor(14.5857, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5783, grad_fn=<NllLossBackward>)\n",
      "tensor(12.7791, grad_fn=<NllLossBackward>)\n",
      "tensor(17.2364, grad_fn=<NllLossBackward>)\n",
      "tensor(15.5955, grad_fn=<NllLossBackward>)\n",
      "tensor(11.3651, grad_fn=<NllLossBackward>)\n",
      "tensor(12.7258, grad_fn=<NllLossBackward>)\n",
      "tensor(9.5208, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4720, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7594, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0943, grad_fn=<NllLossBackward>)\n",
      "tensor(14.7393, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7800, grad_fn=<NllLossBackward>)\n",
      "tensor(14.0652, grad_fn=<NllLossBackward>)\n",
      "tensor(13.6528, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5288, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6115, grad_fn=<NllLossBackward>)\n",
      "tensor(6.9920, grad_fn=<NllLossBackward>)\n",
      "tensor(6.4720, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5787, grad_fn=<NllLossBackward>)\n",
      "tensor(7.8835, grad_fn=<NllLossBackward>)\n",
      "tensor(6.5597, grad_fn=<NllLossBackward>)\n",
      "tensor(9.4610, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2946, grad_fn=<NllLossBackward>)\n",
      "tensor(8.1889, grad_fn=<NllLossBackward>)\n",
      "tensor(11.7595, grad_fn=<NllLossBackward>)\n",
      "tensor(13.6715, grad_fn=<NllLossBackward>)\n",
      "tensor(8.1774, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6025, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5707, grad_fn=<NllLossBackward>)\n",
      "tensor(12.3693, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6799, grad_fn=<NllLossBackward>)\n",
      "tensor(8.2383, grad_fn=<NllLossBackward>)\n",
      "tensor(7.4536, grad_fn=<NllLossBackward>)\n",
      "tensor(7.9551, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8267, grad_fn=<NllLossBackward>)\n",
      "tensor(13.1490, grad_fn=<NllLossBackward>)\n",
      "tensor(10.0953, grad_fn=<NllLossBackward>)\n",
      "tensor(9.1139, grad_fn=<NllLossBackward>)\n",
      "tensor(5.7160, grad_fn=<NllLossBackward>)\n",
      "tensor(4.9527, grad_fn=<NllLossBackward>)\n",
      "tensor(6.4024, grad_fn=<NllLossBackward>)\n",
      "tensor(5.6183, grad_fn=<NllLossBackward>)\n",
      "tensor(5.9600, grad_fn=<NllLossBackward>)\n",
      "tensor(7.2347, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8022, grad_fn=<NllLossBackward>)\n",
      "tensor(9.4996, grad_fn=<NllLossBackward>)\n",
      "tensor(8.2171, grad_fn=<NllLossBackward>)\n",
      "tensor(9.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0259, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|âââââ                                | 1131/10000 [00:05<00:34, 260.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.2769, grad_fn=<NllLossBackward>)\n",
      "tensor(5.9682, grad_fn=<NllLossBackward>)\n",
      "tensor(9.0993, grad_fn=<NllLossBackward>)\n",
      "tensor(10.5033, grad_fn=<NllLossBackward>)\n",
      "tensor(7.2063, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7287, grad_fn=<NllLossBackward>)\n",
      "tensor(8.5351, grad_fn=<NllLossBackward>)\n",
      "tensor(8.2936, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1646, grad_fn=<NllLossBackward>)\n",
      "tensor(18.0105, grad_fn=<NllLossBackward>)\n",
      "tensor(17.9339, grad_fn=<NllLossBackward>)\n",
      "tensor(13.0483, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9928, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7993, grad_fn=<NllLossBackward>)\n",
      "tensor(7.8641, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9875, grad_fn=<NllLossBackward>)\n",
      "tensor(16.2002, grad_fn=<NllLossBackward>)\n",
      "tensor(15.4644, grad_fn=<NllLossBackward>)\n",
      "tensor(13.1264, grad_fn=<NllLossBackward>)\n",
      "tensor(15.0355, grad_fn=<NllLossBackward>)\n",
      "tensor(10.7315, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3528, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7552, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3510, grad_fn=<NllLossBackward>)\n",
      "tensor(11.4612, grad_fn=<NllLossBackward>)\n",
      "tensor(16.1149, grad_fn=<NllLossBackward>)\n",
      "tensor(19.1342, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9214, grad_fn=<NllLossBackward>)\n",
      "tensor(5.9563, grad_fn=<NllLossBackward>)\n",
      "tensor(6.7501, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8982, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0567, grad_fn=<NllLossBackward>)\n",
      "tensor(8.6738, grad_fn=<NllLossBackward>)\n",
      "tensor(7.2800, grad_fn=<NllLossBackward>)\n",
      "tensor(4.1586, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5223, grad_fn=<NllLossBackward>)\n",
      "tensor(14.5984, grad_fn=<NllLossBackward>)\n",
      "tensor(15.8490, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6167, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6187, grad_fn=<NllLossBackward>)\n",
      "tensor(14.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(18.9670, grad_fn=<NllLossBackward>)\n",
      "tensor(22.7579, grad_fn=<NllLossBackward>)\n",
      "tensor(12.6754, grad_fn=<NllLossBackward>)\n",
      "tensor(9.4179, grad_fn=<NllLossBackward>)\n",
      "tensor(7.7140, grad_fn=<NllLossBackward>)\n",
      "tensor(8.4552, grad_fn=<NllLossBackward>)\n",
      "tensor(12.4680, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0106, grad_fn=<NllLossBackward>)\n",
      "tensor(9.5595, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6221, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|âââââ                                | 1185/10000 [00:05<00:34, 252.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.8286, grad_fn=<NllLossBackward>)\n",
      "tensor(13.8918, grad_fn=<NllLossBackward>)\n",
      "tensor(16.4933, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9848, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7426, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7910, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(14.1767, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8934, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5778, grad_fn=<NllLossBackward>)\n",
      "tensor(7.9700, grad_fn=<NllLossBackward>)\n",
      "tensor(10.5141, grad_fn=<NllLossBackward>)\n",
      "tensor(15.9276, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2387, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2723, grad_fn=<NllLossBackward>)\n",
      "tensor(6.6043, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2955, grad_fn=<NllLossBackward>)\n",
      "tensor(12.1772, grad_fn=<NllLossBackward>)\n",
      "tensor(11.8800, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0287, grad_fn=<NllLossBackward>)\n",
      "tensor(7.2096, grad_fn=<NllLossBackward>)\n",
      "tensor(9.0182, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6014, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9782, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0175, grad_fn=<NllLossBackward>)\n",
      "tensor(13.3051, grad_fn=<NllLossBackward>)\n",
      "tensor(16.2527, grad_fn=<NllLossBackward>)\n",
      "tensor(16.2076, grad_fn=<NllLossBackward>)\n",
      "tensor(14.1313, grad_fn=<NllLossBackward>)\n",
      "tensor(13.0173, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8864, grad_fn=<NllLossBackward>)\n",
      "tensor(7.8557, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0349, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4793, grad_fn=<NllLossBackward>)\n",
      "tensor(14.5869, grad_fn=<NllLossBackward>)\n",
      "tensor(17.3072, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6665, grad_fn=<NllLossBackward>)\n",
      "tensor(6.9473, grad_fn=<NllLossBackward>)\n",
      "tensor(7.4755, grad_fn=<NllLossBackward>)\n",
      "tensor(13.2929, grad_fn=<NllLossBackward>)\n",
      "tensor(15.3277, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4128, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4923, grad_fn=<NllLossBackward>)\n",
      "tensor(7.3588, grad_fn=<NllLossBackward>)\n",
      "tensor(7.3555, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9492, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7634, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1893, grad_fn=<NllLossBackward>)\n",
      "tensor(13.3140, grad_fn=<NllLossBackward>)\n",
      "tensor(11.3802, grad_fn=<NllLossBackward>)\n",
      "tensor(11.7299, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|âââââ                                | 1238/10000 [00:05<00:34, 257.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.7302, grad_fn=<NllLossBackward>)\n",
      "tensor(7.1608, grad_fn=<NllLossBackward>)\n",
      "tensor(5.4395, grad_fn=<NllLossBackward>)\n",
      "tensor(5.6807, grad_fn=<NllLossBackward>)\n",
      "tensor(4.4487, grad_fn=<NllLossBackward>)\n",
      "tensor(5.5723, grad_fn=<NllLossBackward>)\n",
      "tensor(4.1876, grad_fn=<NllLossBackward>)\n",
      "tensor(4.7799, grad_fn=<NllLossBackward>)\n",
      "tensor(4.4894, grad_fn=<NllLossBackward>)\n",
      "tensor(5.0098, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6965, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9870, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2439, grad_fn=<NllLossBackward>)\n",
      "tensor(6.7953, grad_fn=<NllLossBackward>)\n",
      "tensor(4.0657, grad_fn=<NllLossBackward>)\n",
      "tensor(4.0795, grad_fn=<NllLossBackward>)\n",
      "tensor(4.7253, grad_fn=<NllLossBackward>)\n",
      "tensor(5.3530, grad_fn=<NllLossBackward>)\n",
      "tensor(12.4647, grad_fn=<NllLossBackward>)\n",
      "tensor(10.3817, grad_fn=<NllLossBackward>)\n",
      "tensor(10.0149, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6011, grad_fn=<NllLossBackward>)\n",
      "tensor(6.9320, grad_fn=<NllLossBackward>)\n",
      "tensor(7.7368, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8039, grad_fn=<NllLossBackward>)\n",
      "tensor(5.3651, grad_fn=<NllLossBackward>)\n",
      "tensor(6.3097, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8740, grad_fn=<NllLossBackward>)\n",
      "tensor(5.2797, grad_fn=<NllLossBackward>)\n",
      "tensor(5.7090, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8062, grad_fn=<NllLossBackward>)\n",
      "tensor(7.4052, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0054, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6389, grad_fn=<NllLossBackward>)\n",
      "tensor(6.5223, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7548, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1471, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7588, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5616, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7123, grad_fn=<NllLossBackward>)\n",
      "tensor(8.8181, grad_fn=<NllLossBackward>)\n",
      "tensor(5.6590, grad_fn=<NllLossBackward>)\n",
      "tensor(5.3794, grad_fn=<NllLossBackward>)\n",
      "tensor(4.6157, grad_fn=<NllLossBackward>)\n",
      "tensor(4.3592, grad_fn=<NllLossBackward>)\n",
      "tensor(8.5026, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8511, grad_fn=<NllLossBackward>)\n",
      "tensor(8.2206, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5800, grad_fn=<NllLossBackward>)\n",
      "tensor(10.9776, grad_fn=<NllLossBackward>)\n",
      "tensor(5.7679, grad_fn=<NllLossBackward>)\n",
      "tensor(6.1561, grad_fn=<NllLossBackward>)\n",
      "tensor(7.3675, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|âââââ                                | 1291/10000 [00:06<00:33, 258.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.6897, grad_fn=<NllLossBackward>)\n",
      "tensor(9.8106, grad_fn=<NllLossBackward>)\n",
      "tensor(8.4123, grad_fn=<NllLossBackward>)\n",
      "tensor(7.3370, grad_fn=<NllLossBackward>)\n",
      "tensor(6.5237, grad_fn=<NllLossBackward>)\n",
      "tensor(6.7629, grad_fn=<NllLossBackward>)\n",
      "tensor(3.0368, grad_fn=<NllLossBackward>)\n",
      "tensor(2.9017, grad_fn=<NllLossBackward>)\n",
      "tensor(2.7260, grad_fn=<NllLossBackward>)\n",
      "tensor(4.9038, grad_fn=<NllLossBackward>)\n",
      "tensor(4.6522, grad_fn=<NllLossBackward>)\n",
      "tensor(6.3171, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5874, grad_fn=<NllLossBackward>)\n",
      "tensor(6.9585, grad_fn=<NllLossBackward>)\n",
      "tensor(9.3830, grad_fn=<NllLossBackward>)\n",
      "tensor(6.8618, grad_fn=<NllLossBackward>)\n",
      "tensor(5.1000, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0320, grad_fn=<NllLossBackward>)\n",
      "tensor(10.1439, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2491, grad_fn=<NllLossBackward>)\n",
      "tensor(12.4237, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6277, grad_fn=<NllLossBackward>)\n",
      "tensor(14.1576, grad_fn=<NllLossBackward>)\n",
      "tensor(14.7937, grad_fn=<NllLossBackward>)\n",
      "tensor(8.6192, grad_fn=<NllLossBackward>)\n",
      "tensor(9.1110, grad_fn=<NllLossBackward>)\n",
      "tensor(7.9383, grad_fn=<NllLossBackward>)\n",
      "tensor(8.1765, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2268, grad_fn=<NllLossBackward>)\n",
      "tensor(7.7568, grad_fn=<NllLossBackward>)\n",
      "tensor(5.4862, grad_fn=<NllLossBackward>)\n",
      "tensor(5.3315, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3355, grad_fn=<NllLossBackward>)\n",
      "tensor(5.8564, grad_fn=<NllLossBackward>)\n",
      "tensor(13.1035, grad_fn=<NllLossBackward>)\n",
      "tensor(13.9865, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0659, grad_fn=<NllLossBackward>)\n",
      "tensor(6.2614, grad_fn=<NllLossBackward>)\n",
      "tensor(5.3938, grad_fn=<NllLossBackward>)\n",
      "tensor(6.9755, grad_fn=<NllLossBackward>)\n",
      "tensor(6.7902, grad_fn=<NllLossBackward>)\n",
      "tensor(11.0154, grad_fn=<NllLossBackward>)\n",
      "tensor(9.5442, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3435, grad_fn=<NllLossBackward>)\n",
      "tensor(4.5044, grad_fn=<NllLossBackward>)\n",
      "tensor(4.6700, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3582, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3481, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2313, grad_fn=<NllLossBackward>)\n",
      "tensor(14.3431, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|âââââ                                | 1343/10000 [00:06<00:34, 248.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.5402, grad_fn=<NllLossBackward>)\n",
      "tensor(11.5860, grad_fn=<NllLossBackward>)\n",
      "tensor(15.7231, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9162, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9719, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5769, grad_fn=<NllLossBackward>)\n",
      "tensor(8.4985, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1299, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6801, grad_fn=<NllLossBackward>)\n",
      "tensor(4.5444, grad_fn=<NllLossBackward>)\n",
      "tensor(5.7848, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5093, grad_fn=<NllLossBackward>)\n",
      "tensor(5.7140, grad_fn=<NllLossBackward>)\n",
      "tensor(4.6585, grad_fn=<NllLossBackward>)\n",
      "tensor(5.1967, grad_fn=<NllLossBackward>)\n",
      "tensor(6.9866, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7897, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7043, grad_fn=<NllLossBackward>)\n",
      "tensor(11.7557, grad_fn=<NllLossBackward>)\n",
      "tensor(6.1606, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3589, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6636, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9173, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0902, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1186, grad_fn=<NllLossBackward>)\n",
      "tensor(13.4552, grad_fn=<NllLossBackward>)\n",
      "tensor(6.8216, grad_fn=<NllLossBackward>)\n",
      "tensor(8.7883, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2166, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2845, grad_fn=<NllLossBackward>)\n",
      "tensor(12.2065, grad_fn=<NllLossBackward>)\n",
      "tensor(10.4254, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7519, grad_fn=<NllLossBackward>)\n",
      "tensor(17.2153, grad_fn=<NllLossBackward>)\n",
      "tensor(15.7646, grad_fn=<NllLossBackward>)\n",
      "tensor(9.4179, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0887, grad_fn=<NllLossBackward>)\n",
      "tensor(8.4479, grad_fn=<NllLossBackward>)\n",
      "tensor(5.2164, grad_fn=<NllLossBackward>)\n",
      "tensor(3.4548, grad_fn=<NllLossBackward>)\n",
      "tensor(5.8150, grad_fn=<NllLossBackward>)\n",
      "tensor(6.3393, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6360, grad_fn=<NllLossBackward>)\n",
      "tensor(10.1980, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7289, grad_fn=<NllLossBackward>)\n",
      "tensor(8.5987, grad_fn=<NllLossBackward>)\n",
      "tensor(6.4248, grad_fn=<NllLossBackward>)\n",
      "tensor(4.1957, grad_fn=<NllLossBackward>)\n",
      "tensor(4.2605, grad_fn=<NllLossBackward>)\n",
      "tensor(7.4494, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|ââââââ                               | 1395/10000 [00:06<00:34, 249.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.9820, grad_fn=<NllLossBackward>)\n",
      "tensor(12.3129, grad_fn=<NllLossBackward>)\n",
      "tensor(7.9985, grad_fn=<NllLossBackward>)\n",
      "tensor(5.1132, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6060, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2037, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3515, grad_fn=<NllLossBackward>)\n",
      "tensor(9.3004, grad_fn=<NllLossBackward>)\n",
      "tensor(6.8180, grad_fn=<NllLossBackward>)\n",
      "tensor(6.2855, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3076, grad_fn=<NllLossBackward>)\n",
      "tensor(9.6166, grad_fn=<NllLossBackward>)\n",
      "tensor(7.3212, grad_fn=<NllLossBackward>)\n",
      "tensor(5.0829, grad_fn=<NllLossBackward>)\n",
      "tensor(5.0104, grad_fn=<NllLossBackward>)\n",
      "tensor(11.6347, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1719, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0208, grad_fn=<NllLossBackward>)\n",
      "tensor(4.3841, grad_fn=<NllLossBackward>)\n",
      "tensor(6.0862, grad_fn=<NllLossBackward>)\n",
      "tensor(9.0086, grad_fn=<NllLossBackward>)\n",
      "tensor(5.9263, grad_fn=<NllLossBackward>)\n",
      "tensor(4.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(4.4049, grad_fn=<NllLossBackward>)\n",
      "tensor(10.1542, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5902, grad_fn=<NllLossBackward>)\n",
      "tensor(7.1417, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2383, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2353, grad_fn=<NllLossBackward>)\n",
      "tensor(10.0640, grad_fn=<NllLossBackward>)\n",
      "tensor(7.2273, grad_fn=<NllLossBackward>)\n",
      "tensor(7.8074, grad_fn=<NllLossBackward>)\n",
      "tensor(7.7786, grad_fn=<NllLossBackward>)\n",
      "tensor(9.3126, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9169, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1067, grad_fn=<NllLossBackward>)\n",
      "tensor(6.1995, grad_fn=<NllLossBackward>)\n",
      "tensor(5.3073, grad_fn=<NllLossBackward>)\n",
      "tensor(9.1730, grad_fn=<NllLossBackward>)\n",
      "tensor(7.3033, grad_fn=<NllLossBackward>)\n",
      "tensor(7.1125, grad_fn=<NllLossBackward>)\n",
      "tensor(8.2284, grad_fn=<NllLossBackward>)\n",
      "tensor(6.6439, grad_fn=<NllLossBackward>)\n",
      "tensor(4.3790, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8612, grad_fn=<NllLossBackward>)\n",
      "tensor(2.6788, grad_fn=<NllLossBackward>)\n",
      "tensor(5.6220, grad_fn=<NllLossBackward>)\n",
      "tensor(9.7828, grad_fn=<NllLossBackward>)\n",
      "tensor(9.3699, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|ââââââ                               | 1420/10000 [00:06<00:40, 212.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0519, grad_fn=<NllLossBackward>)\n",
      "tensor(12.5044, grad_fn=<NllLossBackward>)\n",
      "tensor(11.1054, grad_fn=<NllLossBackward>)\n",
      "tensor(12.0126, grad_fn=<NllLossBackward>)\n",
      "tensor(10.8978, grad_fn=<NllLossBackward>)\n",
      "tensor(10.2884, grad_fn=<NllLossBackward>)\n",
      "tensor(7.8994, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6213, grad_fn=<NllLossBackward>)\n",
      "tensor(7.5544, grad_fn=<NllLossBackward>)\n",
      "tensor(12.9467, grad_fn=<NllLossBackward>)\n",
      "tensor(17.6714, grad_fn=<NllLossBackward>)\n",
      "tensor(8.9055, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0466, grad_fn=<NllLossBackward>)\n",
      "tensor(5.4914, grad_fn=<NllLossBackward>)\n",
      "tensor(8.1565, grad_fn=<NllLossBackward>)\n",
      "tensor(11.2194, grad_fn=<NllLossBackward>)\n",
      "tensor(5.5174, grad_fn=<NllLossBackward>)\n",
      "tensor(6.3788, grad_fn=<NllLossBackward>)\n",
      "tensor(7.6313, grad_fn=<NllLossBackward>)\n",
      "tensor(6.8971, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6711, grad_fn=<NllLossBackward>)\n",
      "tensor(6.5219, grad_fn=<NllLossBackward>)\n",
      "tensor(5.0510, grad_fn=<NllLossBackward>)\n",
      "tensor(7.0571, grad_fn=<NllLossBackward>)\n",
      "tensor(10.6959, grad_fn=<NllLossBackward>)\n",
      "tensor(12.1367, grad_fn=<NllLossBackward>)\n",
      "tensor(8.3834, grad_fn=<NllLossBackward>)\n",
      "tensor(9.9674, grad_fn=<NllLossBackward>)\n",
      "tensor(12.8596, grad_fn=<NllLossBackward>)\n",
      "tensor(9.2999, grad_fn=<NllLossBackward>)\n",
      "tensor(12.3587, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12942/429380578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mall_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC CLASSIFIER\n",
    "#import skorch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.linear = nn.Linear(768,17)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.linear(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    #x = F.softmax(x)\n",
    "    return x\n",
    "\n",
    "classifier = LinearClassifier()\n",
    "\n",
    "\n",
    "parameters = classifier.parameters()\n",
    "#print(list(parameters))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01)\n",
    "\n",
    "all_loss = []\n",
    "\n",
    "accuracy = torchmetrics.Accuracy()\n",
    "for epoch in tqdm(range(10000)):\n",
    "     \n",
    "  output = classifier(train_x)\n",
    "\n",
    "  loss = criterion(output, train_y)\n",
    "  #print(loss)\n",
    "  all_loss.append(loss.item())\n",
    "  loss.backward()\n",
    "\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "    \n",
    "  if epoch % 1000 == 0 :\n",
    "    classifier.eval()\n",
    "    output_dev = classifier(dev_x)\n",
    "    dev_acc = accuracy(output_dev, dev_y)\n",
    "    train_acc = accuracy(output, train_y)\n",
    "    print(f\"Validation accuracy on batch {epoch}: {dev_acc}\")\n",
    "    print(f\"Training accuracy on batch {epoch}: {train_acc}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is 0.8360797762870789\n"
     ]
    }
   ],
   "source": [
    "classifier.eval()\n",
    "output_test = classifier(test_x)\n",
    "test_acc = accuracy(output_test, test_y)\n",
    "print(\"The test accuracy is\",test_acc.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees\n",
    "\n",
    "For our gold labels, we need to recover the node distances from our parse tree. For this we will use the functionality provided by `ete3`, that allows us to compute that directly. I have provided code that transforms a `TokenTree` to a `Tree` in `ete3` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to transform your conllu tree to an nltk.Tree, for better visualisation\n",
    "\n",
    "def rec_tokentree_to_nltk(tokentree):\n",
    "    token = tokentree.token[\"form\"]\n",
    "    tree_str = f\"({token} {' '.join(rec_tokentree_to_nltk(t) for t in tokentree.children)})\"\n",
    "\n",
    "    return tree_str\n",
    "\n",
    "\n",
    "def tokentree_to_nltk(tokentree):\n",
    "    from nltk import Tree as NLTKTree\n",
    "\n",
    "    tree_str = rec_tokentree_to_nltk(tokentree)\n",
    "\n",
    "    return NLTKTree.fromstring(tree_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ete3\n",
    "from ete3 import Tree as EteTree\n",
    "\n",
    "\n",
    "class FancyTree(EteTree):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, format=1, **kwargs)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.get_ascii(show_internal=True)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "\n",
    "def rec_tokentree_to_ete(tokentree):\n",
    "    idx = str(tokentree.token[\"id\"])\n",
    "    children = tokentree.children\n",
    "    if children:\n",
    "        return f\"({','.join(rec_tokentree_to_ete(t) for t in children)}){idx}\"\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "def tokentree_to_ete(tokentree):\n",
    "    newick_str = rec_tokentree_to_ete(tokentree)\n",
    "\n",
    "    return FancyTree(f\"{newick_str};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   /-2\n",
      "  |\n",
      "  |--3\n",
      "  |\n",
      "  |--4\n",
      "  |\n",
      "  |   /6 /-5\n",
      "  |  |\n",
      "  |  |   /-9\n",
      "  |  |  |\n",
      "  |  |  |--10\n",
      "  |  |  |\n",
      "  |  |  |--11\n",
      "  |  |-8|\n",
      "  |  |  |--12\n",
      "  |-7|  |\n",
      "  |  |  |--13\n",
      "  |  |  |\n",
      "  |  |   \\15/-14\n",
      "-1|  |\n",
      "  |  |   /-16\n",
      "  |  |  |\n",
      "  |  |  |--17\n",
      "  |  |  |\n",
      "  |   \\18   /-19\n",
      "  |     |  |\n",
      "  |     |  |--20\n",
      "  |     |  |\n",
      "  |     |  |-23/-22\n",
      "  |      \\21\n",
      "  |        |--24\n",
      "  |        |\n",
      "  |        |   /-25\n",
      "  |        |  |\n",
      "  |         \\28--26\n",
      "  |           |\n",
      "  |            \\-27\n",
      "  |\n",
      "   \\-29\n"
     ]
    }
   ],
   "source": [
    "# Let's check if it works!\n",
    "# We can read in a corpus using the code that was already provided, and convert it to an ete3 Tree.\n",
    "\n",
    "def parse_corpus(filename):\n",
    "    from conllu import parse_incr\n",
    "\n",
    "    data_file = open(filename, encoding=\"utf-8\")\n",
    "\n",
    "    ud_parses = list(parse_incr(data_file))\n",
    "    \n",
    "    return ud_parses\n",
    "\n",
    "corpus = parse_corpus('data/sample/en_ewt-ud-train.conllu')\n",
    "item = corpus[0]\n",
    "tokentree = item.to_tree()\n",
    "ete3_tree = tokentree_to_ete(tokentree)\n",
    "print(ete3_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we label a token by its token id (converted to a string). Based on these id's we are going to retrieve the node distances.\n",
    "\n",
    "To create the true distances of a parse tree in our treebank, we are going to use the `.get_distance` method that is provided by `ete3`: http://etetoolkit.org/docs/latest/tutorial/tutorial_trees.html#working-with-branch-distances\n",
    "\n",
    "We will store all these distances in a `torch.Tensor`.\n",
    "\n",
    "Please fill in the gap in the following method. I recommend you to have a good look at Hewitt's blog post  about these node distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_distances(corpus):\n",
    "    all_distances = []\n",
    "    sen_length = [len(i) for i in corpus]\n",
    "    max_length = max(sen_length)\n",
    "\n",
    "    for item in (corpus):\n",
    "        tokentree = item.to_tree()\n",
    "        ete_tree = tokentree_to_ete(tokentree)\n",
    "\n",
    "        sen_len = len(ete_tree.search_nodes())\n",
    "        distances = torch.full((max_length, max_length), -1)\n",
    "\n",
    "        for i in range(sen_len):\n",
    "            for j in range(sen_len):\n",
    "                node_i = ete_tree&f\"{i+1}\"\n",
    "                node_j = ete_tree&f\"{j+1}\"\n",
    "                distances[i][j] = node_i.get_distance(node_j)\n",
    "\n",
    "        all_distances.append(distances)\n",
    "\n",
    "    return all_distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is now to do the previous step the other way around. After all, we are mainly interested in predicting the node distances of a sentence, in order to recreate the corresponding parse tree.\n",
    "\n",
    "Hewitt et al. reconstruct a parse tree based on a _minimum spanning tree_ (MST, https://en.wikipedia.org/wiki/Minimum_spanning_tree). Fortunately for us, we can simply import a method from `scipy` that retrieves this MST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "import torch\n",
    "\n",
    "\n",
    "def create_mst(distances):\n",
    "    distances = torch.triu(distances).detach().numpy()\n",
    "    \n",
    "    mst = minimum_spanning_tree(distances).toarray()\n",
    "    mst[mst>0] = 1.\n",
    "    \n",
    "    return mst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what this looks like, by looking at a relatively short sentence in the sample corpus.\n",
    "\n",
    "If your addition to the `create_gold_distances` method has been correct, you should be able to run the following snippet. This then shows you the original parse tree, the distances between the nodes, and the MST that is retrieved from these distances. Can you spot the edges in the MST matrix that correspond to the edges in the parse tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   /2 /-1\n",
      "  |\n",
      "  |--3\n",
      "  |\n",
      "  |--4\n",
      "  |\n",
      "  |   /-6\n",
      "  |  |\n",
      "-5|  |--7\n",
      "  |-8|\n",
      "  |  |   /-9\n",
      "  |  |  |\n",
      "  |   \\12--10\n",
      "  |     |\n",
      "  |      \\-11\n",
      "  |\n",
      "   \\-13 \n",
      "\n",
      "tensor([[0, 1, 3, 3, 2, 4, 4, 3, 5, 5, 5, 4, 3],\n",
      "        [1, 0, 2, 2, 1, 3, 3, 2, 4, 4, 4, 3, 2],\n",
      "        [3, 2, 0, 2, 1, 3, 3, 2, 4, 4, 4, 3, 2],\n",
      "        [3, 2, 2, 0, 1, 3, 3, 2, 4, 4, 4, 3, 2],\n",
      "        [2, 1, 1, 1, 0, 2, 2, 1, 3, 3, 3, 2, 1],\n",
      "        [4, 3, 3, 3, 2, 0, 2, 1, 3, 3, 3, 2, 3],\n",
      "        [4, 3, 3, 3, 2, 2, 0, 1, 3, 3, 3, 2, 3],\n",
      "        [3, 2, 2, 2, 1, 1, 1, 0, 2, 2, 2, 1, 2],\n",
      "        [5, 4, 4, 4, 3, 3, 3, 2, 0, 2, 2, 1, 4],\n",
      "        [5, 4, 4, 4, 3, 3, 3, 2, 2, 0, 2, 1, 4],\n",
      "        [5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 0, 1, 4],\n",
      "        [4, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 0, 3],\n",
      "        [3, 2, 2, 2, 1, 3, 3, 2, 4, 4, 4, 3, 0]]) \n",
      "\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "item = corpus[5]\n",
    "tokentree = item.to_tree()\n",
    "ete3_tree = tokentree_to_ete(tokentree)\n",
    "print(ete3_tree, '\\n')\n",
    "\n",
    "gold_distance = create_gold_distances(corpus[5:6])[0]\n",
    "print(gold_distance, '\\n')\n",
    "\n",
    "mst = create_mst(gold_distance)\n",
    "print(mst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are able to map edge distances back to parse trees, we can create code for our quantitative evaluation. For this we will use the Undirected Unlabeled Attachment Score (UUAS), which is expressed as:\n",
    "\n",
    "$$\\frac{\\text{number of predicted edges that are an edge in the gold parse tree}}{\\text{number of edges in the gold parse tree}}$$\n",
    "\n",
    "To do this, we will need to obtain all the edges from our MST matrix. Note that, since we are using undirected trees, that an edge can be expressed in 2 ways: an edge between node $i$ and node $j$ is denoted by both `mst[i,j] = 1`, or `mst[j,i] = 1`.\n",
    "\n",
    "You will write code that computes the UUAS score for a matrix of predicted distances, and the corresponding gold distances. I recommend you to split this up into 2 methods: 1 that retrieves the edges that are present in an MST matrix, and one general method that computes the UUAS score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges(mst):\n",
    "    edges = set()\n",
    "    n_nodes = mst.shape[0]\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(n_nodes):\n",
    "            if mst[i][j] == 1:\n",
    "                edges.append((i+1, j+1))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def calc_uuas(pred_distances, gold_distances):\n",
    "    \n",
    "    gold_mst = create_mst(gold_distances)\n",
    "    pred_mst = create_mst(pred_distances)\n",
    "    pred_edges = edges(pred_mst)\n",
    "    gold_edges = edges(gold_mst)\n",
    "    pred_in_gold = len(pred_edges.intersection(gold_edges))\n",
    "    uuas = pred_in_gold/len(gold_distances)\n",
    "    \n",
    "    return uuas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Probes\n",
    "\n",
    "We now have everything in place to start doing the actual exciting stuff: training our structural probe!\n",
    "    \n",
    "To make life easier for you, we will simply take the `torch` code for this probe from John Hewitt's repository. This allows you to focus on the training regime from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class StructuralProbe(nn.Module):\n",
    "    \"\"\" Computes squared L2 distance after projection by a matrix.\n",
    "    For a batch of sentences, computes all n^2 pairs of distances\n",
    "    for each sentence in the batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_dim, rank, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.probe_rank = rank\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.proj = nn.Parameter(data = torch.zeros(self.model_dim, self.probe_rank))\n",
    "        \n",
    "        nn.init.uniform_(self.proj, -0.05, 0.05)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\" Computes all n^2 pairs of distances after projection\n",
    "        for each sentence in a batch.\n",
    "        Note that due to padding, some distances will be non-zero for pads.\n",
    "        Computes (B(h_i-h_j))^T(B(h_i-h_j)) for all i,j\n",
    "        Args:\n",
    "          batch: a batch of word representations of the shape\n",
    "            (batch_size, max_seq_len, representation_dim)\n",
    "        Returns:\n",
    "          A tensor of distances of shape (batch_size, max_seq_len, max_seq_len)\n",
    "        \"\"\"\n",
    "        transformed = torch.matmul(batch, self.proj)\n",
    "        \n",
    "        batchlen, seqlen, rank = transformed.size()\n",
    "        \n",
    "        transformed = transformed.unsqueeze(2)\n",
    "        transformed = transformed.expand(-1, -1, seqlen, -1)\n",
    "        transposed = transformed.transpose(1,2)\n",
    "        \n",
    "        diffs = transformed - transposed\n",
    "        \n",
    "        squared_diffs = diffs.pow(2)\n",
    "        squared_distances = torch.sum(squared_diffs, -1)\n",
    "\n",
    "        return squared_distances\n",
    "\n",
    "    \n",
    "class L1DistanceLoss(nn.Module):\n",
    "    \"\"\"Custom L1 loss for distance matrices.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, predictions, label_batch, length_batch):\n",
    "        \"\"\" Computes L1 loss on distance matrices.\n",
    "        Ignores all entries where label_batch=-1\n",
    "        Normalizes first within sentences (by dividing by the square of the sentence length)\n",
    "        and then across the batch.\n",
    "        Args:\n",
    "          predictions: A pytorch batch of predicted distances\n",
    "          label_batch: A pytorch batch of true distances\n",
    "          length_batch: A pytorch batch of sentence lengths\n",
    "        Returns:\n",
    "          A tuple of:\n",
    "            batch_loss: average loss in the batch\n",
    "            total_sents: number of sentences in the batch\n",
    "        \"\"\"\n",
    "        labels_1s = (label_batch != -1).float()\n",
    "        predictions_masked = predictions * labels_1s\n",
    "        labels_masked = label_batch * labels_1s\n",
    "        total_sents = torch.sum((length_batch != 0)).float()\n",
    "        squared_lengths = length_batch.pow(2).float()\n",
    "\n",
    "        if total_sents > 0:\n",
    "            loss_per_sent = torch.sum(torch.abs(predictions_masked - labels_masked), dim=(1,2))\n",
    "            #print(\"This is loss per sentence shape\", loss_per_sent.shape)\n",
    "            #print(\"This is squared length shape\", squared_lengths.shape)\n",
    "            normalized_loss_per_sent = loss_per_sent / squared_lengths\n",
    "            batch_loss = torch.sum(normalized_loss_per_sent) / total_sents\n",
    "        \n",
    "        else:\n",
    "            batch_loss = torch.tensor(0.0)\n",
    "        \n",
    "        return batch_loss, total_sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sen_reps_tree(ud_parses: List[TokenList], model, tokenizer, concat=False) -> Tensor:\n",
    "    representation_size = 768\n",
    "    out = []\n",
    "    index = 0\n",
    "    sen_length = [len(i) for i in ud_parses]\n",
    "    max_length = max(sen_length)\n",
    "    \n",
    "    for sentence in tqdm(ud_parses):\n",
    "        j = 0\n",
    "        concat_dict = {}\n",
    "        token_list = []\n",
    "        space_after = False\n",
    "        for token in sentence:\n",
    "            \n",
    "            test_var = token[\"misc\"]\n",
    "            \n",
    "            if space_after:\n",
    "                token_return = tokenizer.encode(str(token), add_prefix_space=True)\n",
    "            else:\n",
    "                token_return = tokenizer.encode(str(token))\n",
    "            if test_var:\n",
    "                space_after = False\n",
    "            else:\n",
    "                space_after = True        \n",
    "            \n",
    "            len_i = len(token_return)\n",
    "            concat_dict[j] = [j+i for i in range(len_i)]\n",
    "            j += len_i\n",
    "            token_list += token_return\n",
    "        token_list = torch.LongTensor(token_list)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            out_sentence = model(input_ids = token_list, output_hidden_states=True)\n",
    "        out_sentence = out_sentence[\"hidden_states\"][-1].squeeze()  \n",
    "        \n",
    "        \n",
    "        out_sent = torch.zeros(max_length, representation_size)\n",
    "        for i, key in enumerate(concat_dict):\n",
    "            out_sent[i] = torch.mean(out_sentence[concat_dict[key]], axis=0)\n",
    "        out.append(out_sent)\n",
    "    \n",
    "    out = torch.stack(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââââââ| 2/2 [00:00<00:00, 14.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0792,  0.3346, -0.1135,  ..., -0.2124,  0.1306, -0.1681],\n",
       "         [-0.3783,  0.0423, -0.0740,  ..., -0.0850,  0.4072, -0.2320],\n",
       "         [-0.4129,  0.4578, -0.7827,  ...,  0.0322, -0.5836,  0.4090],\n",
       "         ...,\n",
       "         [ 0.7832,  0.8050,  0.0341,  ..., -0.1987, -0.6397,  0.0914],\n",
       "         [ 0.5115,  0.4130, -0.8091,  ...,  0.1806, -0.1424,  0.2259],\n",
       "         [-0.8412,  0.2163,  0.0278,  ..., -0.1575, -0.1994, -0.0057]],\n",
       "\n",
       "        [[-0.1087,  0.3302, -0.0595,  ..., -0.1555,  0.1397, -0.1980],\n",
       "         [ 0.5315, -0.1347,  0.6371,  ...,  0.4578,  0.1667,  0.2503],\n",
       "         [ 0.3531,  0.0395, -0.6217,  ..., -0.0975,  0.2088,  0.0475],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_sen_reps_tree(ud_parses[:2], model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have provided a rough outline for the training regime that you can use. Note that the hyper parameters that I provide here only serve as an indication, but should be (briefly) explored by yourself.\n",
    "\n",
    "As can be seen in Hewitt's code above, there exists functionality in the probe to deal with batched input. It is up to you to use that: a (less efficient) method can still incorporate batches by doing multiple forward passes for a batch and computing the backward pass only once for the summed losses of all these forward passes. (_I know, this is not the way to go, but in the interest of time that is allowed ;-), the purpose of the assignment is writing a good paper after all_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "'''\n",
    "Similar to the `create_data` method of the previous notebook, I recommend you to use a method \n",
    "that initialises all the data of a corpus. Note that for your embeddings you can use the \n",
    "`fetch_sen_reps` method again. However, for the POS probe you concatenated all these representations into \n",
    "1 big tensor of shape (num_tokens_in_corpus, model_dim). \n",
    "\n",
    "The StructuralProbe expects its input to contain all the representations of 1 sentence, so I recommend you\n",
    "to update your `fetch_sen_reps` method in a way that it is easy to retrieve all the representations that \n",
    "correspond to a single sentence.\n",
    "''' \n",
    "\n",
    "def init_corpus(path, concat=False, cutoff=None):\n",
    "    \"\"\" Initialises the data of a corpus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to corpus location\n",
    "    concat : bool, optional\n",
    "        Optional toggle to concatenate all the tensors\n",
    "        returned by `fetch_sen_reps`.\n",
    "    cutoff : int, optional\n",
    "        Optional integer to \"cutoff\" the data in the corpus.\n",
    "        This allows only a subset to be used, alleviating \n",
    "        memory usage.\n",
    "    \"\"\"\n",
    "    corpus = parse_corpus(path)[:cutoff]\n",
    "\n",
    "    embs = fetch_sen_reps_tree(corpus, model, tokenizer, concat=concat)    \n",
    "    gold_distances = torch.stack(create_gold_distances(corpus))\n",
    "    \n",
    "    return embs, gold_distances\n",
    "\n",
    "\n",
    "# I recommend you to write a method that can evaluate the UUAS & loss score for the dev (& test) corpus.\n",
    "# Feel free to alter the signature of this method.\n",
    "def evaluate_probe(probe, _data):\n",
    "    probe.eval()\n",
    "    x, y = _data\n",
    "    loss_function =  L1DistanceLoss()\n",
    "    output = probe(x)\n",
    "    loss_score = loss_function(output, y)\n",
    "    uuas_score = calc_uuas(output, y)\n",
    "    \n",
    "    \n",
    "    return loss_score, uuas_score\n",
    "\n",
    "\n",
    "# Feel free to alter the signature of this method.\n",
    "def train(_data):\n",
    "    emb_dim = 768\n",
    "    rank = 64\n",
    "    lr = 10e-4\n",
    "    batch_size = 24\n",
    "    epochs = 100\n",
    "\n",
    "    probe = StructuralProbe(emb_dim, rank)\n",
    "    optimizer = optim.Adam(probe.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,patience=1)\n",
    "    loss_function =  L1DistanceLoss()\n",
    "    x, y = _data\n",
    "    dev_losses = []\n",
    "    dev_uuass = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        for i in range(0, len(corpus), batch_size):\n",
    "            x_batch, y_batch = x[i:i+batch_size], y[i:i+batch_size]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = probe(x_batch)\n",
    "            #print(x_batch)\n",
    "            length_batch = torch.count_nonzero(x_batch, dim=1)\n",
    "            batch_loss, _ = loss_function(output, y_batch, length_batch[:,0])\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        dev_loss, dev_uuas = evaluate_probe(probe, _dev_data)\n",
    "        dev_losses.append(dev_loss)\n",
    "        dev_uuass.append(dev_uuas)\n",
    "\n",
    "        # Using a scheduler is up to you, and might require some hyper param fine-tuning\n",
    "        scheduler.step(dev_loss)\n",
    "\n",
    "    test_loss, test_uuas = evaluate_probe(probe, _test_data)\n",
    "    return dev_losses, dev_uuas, test_loss, test_uuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 300/300 [00:13<00:00, 21.45it/s]\n",
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 100/100 [00:04<00:00, 20.12it/s]\n",
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 100/100 [00:06<00:00, 15.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_data = init_corpus(os.path.join('', 'data/en_ewt-ud-train.conllu'), cutoff=300)\n",
    "_dev_data = init_corpus(os.path.join('', 'data/en_ewt-ud-train.conllu'), cutoff=100)\n",
    "_test_data = init_corpus(os.path.join('', 'data/en_ewt-ud-train.conllu'), cutoff=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'length_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12942/3578222267.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_uuas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_uuas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_12942/810350012.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(_data)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mdev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_uuas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_probe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mdev_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mdev_uuass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_uuas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12942/810350012.py\u001b[0m in \u001b[0;36mevaluate_probe\u001b[0;34m(probe, _data)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mL1DistanceLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mloss_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0muuas_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_uuas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'length_batch'"
     ]
    }
   ],
   "source": [
    "dev_losses, dev_uuas, test_loss, test_uuas = train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTeX trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your report you might want to add some of those fancy dependency tree plots like those of Figure 2 in the Structural Probing paper. For that you can use the following code, that outputs the corresponding LaTeX markup.\n",
    "\n",
    "**N.B.**: for the latex tikz tree the first token in a sentence has index 1 (instead of 0), so take that into account with the predicted and gold edges that you pass to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tikz(predicted_edges, gold_edges, words):\n",
    "    \"\"\" Turns edge sets on word (nodes) into tikz dependency LaTeX.\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted_edges : Set[Tuple[int, int]]\n",
    "        Set (or list) of edge tuples, as predicted by your probe.\n",
    "    gold_edges : Set[Tuple[int, int]]\n",
    "        Set (or list) of gold edge tuples, as obtained from the treebank.\n",
    "    words : List[str]\n",
    "        List of strings representing the tokens in the sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    string = \"\"\"\\\\begin{dependency}[hide label, edge unit distance=.5ex]\n",
    "    \\\\begin{deptext}[column sep=0.05cm]\n",
    "    \"\"\"\n",
    "\n",
    "    string += (\n",
    "        \"\\\\& \".join([x.replace(\"$\", \"\\$\").replace(\"&\", \"+\") for x in words])\n",
    "        + \" \\\\\\\\\\n\"\n",
    "    )\n",
    "    string += \"\\\\end{deptext}\" + \"\\n\"\n",
    "    for i_index, j_index in gold_edges:\n",
    "        string += \"\\\\depedge[-]{{{}}}{{{}}}{{{}}}\\n\".format(i_index, j_index, \".\")\n",
    "    for i_index, j_index in predicted_edges:\n",
    "        string += f\"\\\\depedge[-,edge style={{red!60!}}, edge below]{{{i_index}}}{{{j_index}}}{{.}}\\n\"\n",
    "    string += \"\\\\end{dependency}\\n\"\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
